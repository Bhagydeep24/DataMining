{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Name: Deep Bipinbhai Patel, ID: 1001765854, Subject: Data Mining </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The goal of this assignment is to learn about the Naive Bayes Classifier (NBC).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use text dataset about the movie review. Your goal is predicting the sentiment.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;A. http://ai.stanford.edu/~amaas/data/sentiment/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:\n",
      "[['for', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem', 'imagine', 'a', 'movie', 'where', 'joe', 'piscopo', 'is', 'actually', 'funny', 'maureen', 'stapleton', 'is', 'a', 'scene', 'stealer', 'the', 'moroni', 'character', 'is', 'an', 'absolute', 'scream', 'watch', 'for', 'alan', 'the', 'skipper', 'hale', 'jr', 'as', 'a', 'police', 'sgt', 1], ['bizarre', 'horror', 'movie', 'filled', 'with', 'famous', 'faces', 'but', 'stolen', 'by', 'cristina', 'raines', 'later', 'of', \"tv's\", 'flamingo', 'road', 'as', 'a', 'pretty', 'but', 'somewhat', 'unstable', 'model', 'with', 'a', 'gummy', 'smile', 'who', 'is', 'slated', 'to', 'pay', 'for', 'her', 'attempted', 'suicides', 'by', 'guarding', 'the', 'gateway', 'to', 'hell', 'the', 'scenes', 'with', 'raines', 'modeling', 'are', 'very', 'well', 'captured', 'the', 'mood', 'music', 'is', 'perfect', 'deborah', 'raffin', 'is', 'charming', 'as', \"cristina's\", 'pal', 'but', 'when', 'raines', 'moves', 'into', 'a', 'creepy', 'brooklyn', 'heights', 'brownstone', 'inhabited', 'by', 'a', 'blind', 'priest', 'on', 'the', 'top', 'floor', 'things', 'really', 'start', 'cooking', 'the', 'neighbors', 'including', 'a', 'fantastically', 'wicked', 'burgess', 'meredith', 'and', 'kinky', 'couple', 'sylvia', 'miles', 'beverly', \"d'angelo\", 'are', 'a', 'diabolical', 'lot', 'and', 'eli', 'wallach', 'is', 'great', 'fun', 'as', 'a', 'wily', 'police', 'detective', 'the', 'movie', 'is', 'nearly', 'a', 'cross', 'pollination', 'of', \"rosemary's\", 'baby', 'and', 'the', 'exorcist', 'but', 'what', 'a', 'combination', 'based', 'on', 'the', 'best', 'seller', 'by', 'jeffrey', 'konvitz', 'the', 'sentinel', 'is', 'entertainingly', 'spooky', 'full', 'of', 'shocks', 'brought', 'off', 'well', 'by', 'director', 'michael', 'winner', 'who', 'mounts', 'a', 'thoughtfully', 'downbeat', 'ending', 'with', 'skill', '1', '2', 'from', 1], ['a', 'solid', 'if', 'unremarkable', 'film', 'matthau', 'as', 'einstein', 'was', 'wonderful', 'my', 'favorite', 'part', 'and', 'the', 'only', 'thing', 'that', 'would', 'make', 'me', 'go', 'out', 'of', 'my', 'way', 'to', 'see', 'this', 'again', 'was', 'the', 'wonderful', 'scene', 'with', 'the', 'physicists', 'playing', 'badmitton', 'i', 'loved', 'the', 'sweaters', 'and', 'the', 'conversation', 'while', 'they', 'waited', 'for', 'robbins', 'to', 'retrieve', 'the', 'birdie', 1]]\n",
      "negative:\n",
      "[['working', 'with', 'one', 'of', 'the', 'best', 'shakespeare', 'sources', 'this', 'film', 'manages', 'to', 'be', 'creditable', 'to', \"it's\", 'source', 'whilst', 'still', 'appealing', 'to', 'a', 'wider', 'audience', 'branagh', 'steals', 'the', 'film', 'from', 'under', \"fishburne's\", 'nose', 'and', \"there's\", 'a', 'talented', 'cast', 'on', 'good', 'form', 0], ['well', 'tremors', 'i', 'the', 'original', 'started', 'off', 'in', '1990', 'and', 'i', 'found', 'the', 'movie', 'quite', 'enjoyable', 'to', 'watch', 'however', 'they', 'proceeded', 'to', 'make', 'tremors', 'ii', 'and', 'iii', 'trust', 'me', 'those', 'movies', 'started', 'going', 'downhill', 'right', 'after', 'they', 'finished', 'the', 'first', 'one', 'i', 'mean', 'ass', 'blasters', 'now', 'only', 'god', 'himself', 'is', 'capable', 'of', 'answering', 'the', 'question', 'why', 'in', 'gods', 'name', 'would', 'they', 'create', 'another', 'one', 'of', 'these', 'dumpster', 'dives', 'of', 'a', 'movie', 'tremors', 'iv', 'cannot', 'be', 'considered', 'a', 'bad', 'movie', 'in', 'fact', 'it', 'cannot', 'be', 'even', 'considered', 'an', 'epitome', 'of', 'a', 'bad', 'movie', 'for', 'it', 'lives', 'up', 'to', 'more', 'than', 'that', 'as', 'i', 'attempted', 'to', 'sit', 'though', 'it', 'i', 'noticed', 'that', 'my', 'eyes', 'started', 'to', 'bleed', 'and', 'i', 'hoped', 'profusely', 'that', 'the', 'little', 'girl', 'from', 'the', 'ring', 'would', 'crawl', 'through', 'the', 'tv', 'and', 'kill', 'me', 'did', 'they', 'really', 'think', 'that', 'dressing', 'the', 'people', 'who', 'had', 'stared', 'in', 'the', 'other', 'movies', 'up', 'as', 'though', 'they', \"we're\", 'from', 'the', 'wild', 'west', 'would', 'make', 'the', 'movie', 'with', 'the', 'exact', 'same', 'occurrences', 'any', 'better', 'honestly', 'i', 'would', 'never', 'suggest', 'buying', 'this', 'movie', 'i', 'mean', 'there', 'are', 'cheaper', 'ways', 'to', 'find', 'things', 'that', 'burn', 'well', 0], ['ouch', 'this', 'one', 'was', 'a', 'bit', 'painful', 'to', 'sit', 'through', 'it', 'has', 'a', 'cute', 'and', 'amusing', 'premise', 'but', 'it', 'all', 'goes', 'to', 'hell', 'from', 'there', 'matthew', 'modine', 'is', 'almost', 'always', 'pedestrian', 'and', 'annoying', 'and', 'he', 'does', 'not', 'disappoint', 'in', 'this', 'one', 'deborah', 'kara', 'unger', 'and', 'john', 'neville', 'turned', 'in', 'surprisingly', 'decent', 'performances', 'alan', 'bates', 'and', 'jennifer', 'tilly', 'among', 'others', 'played', 'it', 'way', 'over', 'the', 'top', 'i', 'know', \"that's\", 'the', 'way', 'the', 'parts', 'were', 'written', 'and', \"it's\", 'hard', 'to', 'blame', 'actors', 'when', 'the', 'script', 'and', 'director', 'have', 'them', 'do', 'such', 'schlock', 'if', \"you're\", 'going', 'to', 'have', 'outrageous', 'characters', \"that's\", 'ok', 'but', 'you', 'gotta', 'have', 'good', 'material', 'to', 'make', 'it', 'work', 'it', \"didn't\", 'here', 'run', 'away', 'screaming', 'from', 'this', 'movie', 'if', 'at', 'all', 'possible', 0]]\n",
      "Merged:\n",
      "[list(['for', 'a', 'movie', 'that', 'gets', 'no', 'respect', 'there', 'sure', 'are', 'a', 'lot', 'of', 'memorable', 'quotes', 'listed', 'for', 'this', 'gem', 'imagine', 'a', 'movie', 'where', 'joe', 'piscopo', 'is', 'actually', 'funny', 'maureen', 'stapleton', 'is', 'a', 'scene', 'stealer', 'the', 'moroni', 'character', 'is', 'an', 'absolute', 'scream', 'watch', 'for', 'alan', 'the', 'skipper', 'hale', 'jr', 'as', 'a', 'police', 'sgt', 1])\n",
      " list(['bizarre', 'horror', 'movie', 'filled', 'with', 'famous', 'faces', 'but', 'stolen', 'by', 'cristina', 'raines', 'later', 'of', \"tv's\", 'flamingo', 'road', 'as', 'a', 'pretty', 'but', 'somewhat', 'unstable', 'model', 'with', 'a', 'gummy', 'smile', 'who', 'is', 'slated', 'to', 'pay', 'for', 'her', 'attempted', 'suicides', 'by', 'guarding', 'the', 'gateway', 'to', 'hell', 'the', 'scenes', 'with', 'raines', 'modeling', 'are', 'very', 'well', 'captured', 'the', 'mood', 'music', 'is', 'perfect', 'deborah', 'raffin', 'is', 'charming', 'as', \"cristina's\", 'pal', 'but', 'when', 'raines', 'moves', 'into', 'a', 'creepy', 'brooklyn', 'heights', 'brownstone', 'inhabited', 'by', 'a', 'blind', 'priest', 'on', 'the', 'top', 'floor', 'things', 'really', 'start', 'cooking', 'the', 'neighbors', 'including', 'a', 'fantastically', 'wicked', 'burgess', 'meredith', 'and', 'kinky', 'couple', 'sylvia', 'miles', 'beverly', \"d'angelo\", 'are', 'a', 'diabolical', 'lot', 'and', 'eli', 'wallach', 'is', 'great', 'fun', 'as', 'a', 'wily', 'police', 'detective', 'the', 'movie', 'is', 'nearly', 'a', 'cross', 'pollination', 'of', \"rosemary's\", 'baby', 'and', 'the', 'exorcist', 'but', 'what', 'a', 'combination', 'based', 'on', 'the', 'best', 'seller', 'by', 'jeffrey', 'konvitz', 'the', 'sentinel', 'is', 'entertainingly', 'spooky', 'full', 'of', 'shocks', 'brought', 'off', 'well', 'by', 'director', 'michael', 'winner', 'who', 'mounts', 'a', 'thoughtfully', 'downbeat', 'ending', 'with', 'skill', '1', '2', 'from', 1])\n",
      " list(['a', 'solid', 'if', 'unremarkable', 'film', 'matthau', 'as', 'einstein', 'was', 'wonderful', 'my', 'favorite', 'part', 'and', 'the', 'only', 'thing', 'that', 'would', 'make', 'me', 'go', 'out', 'of', 'my', 'way', 'to', 'see', 'this', 'again', 'was', 'the', 'wonderful', 'scene', 'with', 'the', 'physicists', 'playing', 'badmitton', 'i', 'loved', 'the', 'sweaters', 'and', 'the', 'conversation', 'while', 'they', 'waited', 'for', 'robbins', 'to', 'retrieve', 'the', 'birdie', 1])]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import string\n",
    "import re\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "# t_data=np.array()\n",
    "tp_dataset=[]\n",
    "tn_dataset=[]\n",
    "\n",
    "def read_file(file_name):\n",
    "    f = open(file_name,'r');\n",
    "    get_text=f.read();\n",
    "    f.close();\n",
    "    return get_text;\n",
    "\n",
    "def get_files(dir_name,class_category):\n",
    "    dataset=[];\n",
    "    for f in os.listdir(dir_name):\n",
    "        txt=read_file(dir_name+\"/\"+f);\n",
    "        html_tags=re.compile('<.*?>');\n",
    "        txt=re.sub(html_tags, '', txt);#remove html tags\n",
    "        txt=re.sub(r\"[^a-zA-Z0-9']+\", ' ', txt);#just keep chars and number and remove rest all punctions\n",
    "        txt=txt.lower().split();#lowercase all the words and split by space.\n",
    "        txt.append(class_category);#Appending 1 or 0 depending on review: 1 for positive and 0 for negative\n",
    "        dataset.append(txt);\n",
    "    return dataset;\n",
    "tp_dataset=get_files(\"/Users/deeppatel/aclImdb/train/pos\",1);\n",
    "tn_dataset=get_files(\"/Users/deeppatel/aclImdb/train/neg\",0);\n",
    "\n",
    "print(\"positive:\");\n",
    "print(tp_dataset[0:3]);\n",
    "print(\"negative:\");\n",
    "print(tn_dataset[0:3]);\n",
    "t_data=np.append(tp_dataset,tn_dataset)\n",
    "print(\"Merged:\");\n",
    "print(t_data[0:3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training folder Dataset after random shuffling:\n",
      "\n",
      "[list(['this', 'movie', 'was', 'the', 'best', 'movie', 'i', 'have', 'ever', 'seen', 'being', 'lds', 'i', 'highly', 'recommend', 'this', 'movie', 'because', 'you', 'are', 'able', 'to', 'feel', 'a', 'more', 'understanding', 'about', 'the', 'life', 'of', 'joseph', 'smith', 'although', 'the', 'movie', 'was', 'not', 'made', 'with', 'highly', 'acclaimed', 'actors', 'it', 'is', 'a', 'remarkable', 'and', 'life', 'changing', 'movie', 'that', 'can', 'be', 'enjoyed', 'and', 'appreciated', 'by', 'everyone', 'i', 'saw', 'this', 'movie', 'with', 'my', 'family', 'and', 'i', 'can', 'bear', 'witness', 'that', 'we', 'have', 'all', 'had', 'a', 'change', 'of', 'heart', 'this', 'movie', 'allows', 'people', 'to', 'really', 'understand', 'how', 'hard', 'the', 'life', 'was', 'for', 'the', 'prophet', 'and', 'how', 'much', 'tribulation', 'he', 'was', 'faced', 'with', 'after', 'i', 'saw', 'this', 'movie', 'there', 'was', 'not', 'a', 'single', 'dry', 'eye', 'in', 'the', 'entire', 'room', 'everyone', 'was', 'touched', 'by', 'what', 'they', 'saw', 'and', 'i', 'have', 'not', 'been', 'the', 'same', 'since', 'i', 'have', 'seen', 'it', 'i', 'highly', 'recommend', 'this', 'movie', 'for', 'everyone', 1])\n",
      " list(['this', 'is', 'an', 'excellent', 'film', 'for', 'female', 'body', 'builder', 'female', 'action', 'fans', 'i', 'think', 'that', 'sue', 'price', 'did', 'a', 'great', 'job', 'in', 'this', 'film', 'series', 'nemesis', '2', '3', '4', 'and', 'proved', 'to', 'be', 'a', 'great', 'fighter', 'she', 'has', 'a', 'very', 'striking', 'appearance', 'and', 'a', 'will', 'of', 'iron', 'to', 'resist', 'the', 'powerful', 'nebula', 'nemesis', '2', 'though', 'not', 'a', 'film', 'of', 'great', 'value', 'and', 'sue', \"price's\", 'acting', 'skills', 'not', 'the', 'best', 'to', 'have', 'met', 'in', 'my', 'life', 'the', 'movie', 'itself', 'was', 'something', 'awesome', 'a', 'priceless', 'gem', 'for', 'fans', 'of', 'female', 'body', 'builder', 'action', 'well', 'some', 'parts', 'of', 'nemesis', '2', 'have', 'been', 'copied', 'by', 'other', 'famous', 'sci', 'fi', 'films', 'such', 'as', 'terminator', 'or', 'predator', 'but', \"that's\", 'not', 'the', 'point', 'the', 'point', 'is', 'that', 'a', 'puyn', 'casted', 'in', 'that', 'film', 'a', 'very', 'talented', 'body', 'builder', 'who', 'put', 'all', 'of', 'her', 'energy', 'and', 'body', 'talent', 'to', 'show', 'us', 'the', 'best', 'she', 'can', 'do', 'i', 'really', 'enjoyed', 'that', 'film', 'and', 'watched', 'with', 'the', 'same', 'enthusiasm', 'nemesis', '3', 'a', 'rather', 'boring', 'sequel', 'and', 'nemesis', '4', 'a', 'much', 'more', 'interesting', 'sequel', 'than', '3', 'what', 'a', 'pity', 'it', \"hasn't\", 'shown', 'yet', 'on', 'dvd', 1])\n",
      " list(['steve', 'carell', 'has', 'made', 'a', 'career', 'out', 'of', 'portraying', 'the', 'slightly', 'odd', 'straight', 'guy', 'first', 'on', \"'the\", 'daily', \"show'\", 'and', 'then', 'in', 'various', 'supporting', 'roles', 'in', 'virgin', 'carell', 'has', 'found', 'a', 'clever', 'and', 'hilarious', 'script', 'that', 'perfectly', 'capitalizes', 'on', 'his', 'strengths', 'carell', 'plays', 'andy', 'stitzer', 'a', 'middle', 'aged', 'man', 'living', 'a', 'quiet', 'lonely', 'life', 'andy', 'is', 'a', 'little', 'odd', 'but', 'in', 'an', 'awkward', 'nice', 'guy', 'sort', 'of', 'way', 'one', 'night', 'while', 'socializing', 'with', 'his', 'co', 'workers', 'for', 'the', 'first', 'time', 'andy', 'accidentally', 'reveals', 'that', 'he', 'is', 'a', 'virgin', 'his', 'co', 'workers', 'david', 'paul', 'rudd', 'jay', 'romany', 'malco', 'and', 'cal', 'seth', 'rogen', 'initially', 'tease', 'andy', 'about', 'his', 'situation', 'but', \"it's\", 'clear', 'that', 'all', 'three', 'have', 'a', 'certain', 'respect', 'for', 'the', 'decent', 'human', 'being', 'that', 'andy', 'is', 'and', 'they', 'resolve', 'to', 'help', 'him', 'out', 'by', 'assisting', 'him', 'in', 'ending', 'his', 'virginity', 'and', 'so', 'begins', \"andy's\", 'quest', 'into', 'adulthood', 'andy', 'is', 'the', 'quintessential', 'innocent', 'and', 'the', 'bulk', 'of', 'the', 'humor', 'derives', 'from', 'his', 'naivet', 'to', 'the', 'situations', 'he', 'finds', 'himself', 'in', 'throughout', 'the', 'film', 'some', 'of', 'the', 'humor', 'is', 'crude', 'gross', 'out', 'stuff', 'but', 'most', 'of', 'it', 'is', 'just', 'well', 'done', 'intelligent', 'comedy', 'in', 'addition', 'i', 'found', 'some', 'parts', 'of', 'the', 'film', 'actually', 'pretty', 'touching', 'as', 'andy', 'finds', 'himself', 'developing', 'both', 'romantic', 'relationships', 'and', 'friendships', 'perhaps', 'for', 'the', 'first', 'time', 'in', 'his', 'life', \"i'm\", 'not', 'trying', 'to', 'portray', 'the', 'movie', 'as', 'a', 'love', 'story', 'or', 'a', 'drama', \"it's\", 'a', 'rolling', 'in', 'your', 'seats', 'comedy', 'still', 'every', 'good', 'comedy', 'i', 'have', 'ever', 'seen', 'contains', 'enough', 'heart', 'for', 'you', 'to', 'care', 'about', 'the', 'characters', 'a', 'good', 'comparison', 'would', 'be', \"'the\", 'wedding', \"crashers'\", 'from', 'earlier', 'this', 'summer', 'virgin', 'has', 'a', 'similar', 'humor', 'but', 'is', 'perhaps', 'a', 'bit', 'more', 'vulgar', 'in', 'some', 'of', 'its', 'jokes', 'i', 'particularly', 'loved', 'the', 'ending', 'of', 'the', 'film', 'which', 'i', 'thought', 'was', 'a', 'perfect', 'way', 'to', 'end', 'the', 'flick', 'without', 'giving', 'anything', 'away', 'it', 'reminded', 'me', 'of', \"'something\", 'about', \"mary'\", 'very', 'light', 'and', 'fun', 'it', 'leaves', 'you', 'laughing', 'and', 'smiling', 'which', 'is', 'exactly', 'how', 'you', 'should', 'feel', 'when', 'you', 'finish', 'a', 'comedy', 'i', 'would', 'highly', 'recommend', 1])\n",
      " list(['the', 'film', 'is', 'bad', 'there', 'is', 'no', 'other', 'way', 'to', 'say', 'it', 'the', 'story', 'is', 'weak', 'and', 'outdated', 'especially', 'for', 'this', 'country', 'i', \"don't\", 'think', 'most', 'people', 'know', 'what', 'a', 'walker', 'is', 'or', 'will', 'really', 'care', 'i', 'felt', 'as', 'if', 'i', 'was', 'watching', 'a', 'movie', 'from', 'the', \"70's\", 'the', 'subject', 'was', 'just', 'not', 'believable', 'for', 'the', 'year', '2007', 'even', 'being', 'set', 'in', 'dc', 'i', 'think', 'this', 'rang', 'true', 'for', 'everyone', 'else', 'who', 'watched', 'it', 'too', 'as', 'the', 'applause', 'were', 'low', 'and', 'quick', 'at', 'the', 'end', 'most', \"didn't\", 'stay', 'for', 'the', 'q', 'a', 'either', 'i', \"don't\", 'think', 'schrader', 'really', 'thought', 'the', 'film', 'out', 'ahead', 'of', 'time', 'many', 'of', 'the', 'scenes', 'seemed', 'to', 'be', 'cut', 'short', 'as', 'if', 'they', 'were', 'never', 'finished', 'or', 'he', 'just', \"didn't\", 'know', 'how', 'to', 'finish', 'them', 'he', 'jumped', 'from', 'one', 'scene', 'to', 'the', 'next', 'and', 'you', 'had', 'to', 'try', 'and', 'figure', 'out', 'or', 'guess', 'what', 'was', 'going', 'on', 'i', 'really', \"didn't\", 'get', \"woody's\", 'carter', 'private', 'life', 'or', 'boyfriend', 'either', 'what', 'were', 'all', 'the', 'artistic', 'male', 'bondage', 'and', 'torture', 'pictures', 'from', 'iraq', 'prisons', 'about', 'what', 'was', 'he', 'thinking', 'i', 'think', 'it', 'was', 'his', 'very', 'poor', 'attempt', 'at', 'trying', 'to', 'create', 'this', 'dark', 'private', 'subculture', 'life', 'for', \"woody's\", 'character', 'car', 'it', \"didn't\", 'work', 'it', \"didn't\", 'even', 'seem', 'to', 'make', 'sense', 'really', 'the', 'only', 'good', 'thing', 'about', 'this', 'film', 'was', 'woody', 'harrelson', 'he', 'played', 'his', 'character', 'car', 'flawlessly', 'you', 'really', 'did', 'get', 'a', 'great', 'sense', 'of', 'what', 'a', 'walker', 'may', 'have', 'been', 'like', 'say', 'twenty', 'years', 'ago', 'he', 'was', 'great', 'and', 'most', 'likely', 'will', 'never', 'get', 'recognized', 'for', 'it', 'as', 'for', 'lauren', 'lily', 'and', 'kristin', 'boring', \"don't\", 'see', 'it', 'it', 'is', 'painful', 'unless', 'you', 'are', 'a', 'true', 'harrelson', 'fan', 0])\n",
      " list(['this', 'film', 'is', 'overblown', 'predictable', 'pretentious', 'and', 'hollow', 'to', 'its', 'core', 'the', 'settings', 'are', 'faithful', 'to', 'the', 'era', 'but', 'self', 'conscious', 'in', 'their', 'magnification', 'by', 'prolonged', 'exposure', 'the', 'lingering', 'over', 'artifacts', 'stops', 'the', 'action', 'and', 'cloys', 'almost', 'as', 'much', 'as', 'the', 'empty', 'dialogue', 'tom', 'hanks', 'seems', 'to', 'be', 'sleepwalking', 'much', 'as', 'bruce', 'willis', 'did', 'in', \"hart's\", 'war', 'tom', 'you', \"can't\", 'give', 'depth', 'to', 'a', 'character', 'simply', 'by', 'making', 'your', 'face', 'blank', 'the', 'content', 'did', 'not', 'warrant', 'the', 'histrionic', 'acting', 'by', 'paul', 'newman', 'this', 'is', 'a', 'dud', 'wrapped', 'in', 'an', 'atomic', 'bomb', 'casing', 0])\n",
      " list(['brokedown', 'palace', 'is', 'not', 'the', 'kind', 'of', 'movie', 'i', 'would', 'ever', 'like', 'to', 'see', 'i', 'also', 'did', 'not', 'like', 'the', 'movie', 'when', 'some', 'aussie', 'man', 'smuggled', 'drugs', 'in', 'thailand', 'and', 'accused', 'claire', 'danes', 'and', 'kate', 'beckinsale', 'of', 'drug', 'smuggling', 'i', 'would', 'not', 'go', 'to', 'that', 'country', 'no', 'matter', 'what', 'after', 'i', 'saw', 'this', 'movie', 'in', 'fact', 'this', 'movie', 'stinks', 'i', 'prefer', 'to', 'visit', 'germany', 'to', 'meet', 'beautiful', 'single', 'women', 'germany', 'is', 'the', 'country', 'i', 'tolerate', 'i', 'also', 'would', 'rather', 'stick', 'to', 'the', 'united', 'states', 'instead', 'after', 'i', 'saw', 'some', 'of', 'the', 'movie', 'in', 'the', 'theatre', 'including', 'the', 'false', 'accusation', 'of', 'drug', 'smuggling', 'i', 'left', 'the', 'theatre', 'and', 'had', 'my', 'money', 'refunded', 'because', 'i', 'cannot', 'tolerate', 'this', 'movie', 'if', 'you', 'are', 'going', 'to', 'to', 'thailand', 'to', 'meet', 'someone', 'there', 'who', 'could', 'be', 'a', 'drug', 'smuggler', 'forget', 'this', 0])\n",
      " list(['i', \"don't\", 'recall', 'walking', 'out', 'of', 'a', 'movie', 'theater', 'except', 'this', 'once', 'not', 'only', 'that', 'but', 'i', 'was', 'with', '7', 'friends', 'and', 'we', 'all', 'wanted', 'to', 'go', 'an', 'uninteresting', 'plot', 'characters', 'made', 'of', 'clay', 'violence', 'with', 'no', 'point', 'i', \"didn't\", 'care', 'when', 'the', 'good', 'guys', 'died', 'i', \"didn't\", 'care', 'when', 'the', 'bad', 'guys', 'got', 'it', 'the', 'fantasy', 'and', 'magic', 'was', 'laid', 'on', 'thick', 'as', 'liver', 'pudding', 'and', 'there', 'was', 'no', 'coherency', 'in', 'short', 'fine', 'entertainment', 'if', 'you', 'happen', 'to', 'be', 'spending', 'an', 'eternity', 'in', 'hell', 0])\n",
      " list(['nightmare', 'weekend', 'is', 'proof', 'positive', 'that', 'some', 'people', 'are', 'so', 'desperate', 'to', 'be', \"'in\", 'the', \"movies'\", 'they', 'are', 'prepared', 'to', 'do', 'almost', 'anything', \"i'm\", 'not', 'referring', 'to', 'the', 'countless', 'women', 'who', 'seem', 'quite', 'happy', 'to', 'appear', 'completely', 'starkers', 'in', 'this', 'dreadful', 'piece', 'of', 'trash', 'after', 'all', 'the', 'naked', 'female', 'form', 'is', 'a', 'beautiful', 'thing', 'and', 'nothing', 'to', 'be', 'ashamed', 'of', 'no', \"i'm\", 'talking', 'about', 'those', 'who', 'are', 'more', 'than', 'willing', 'to', 'co', 'star', 'with', 'a', 'badly', 'made', 'hand', 'puppet', 'called', 'george', 'now', 'that', 'is', 'embarrassing', 'a', 'bio', 'electronic', 'being', 'created', 'by', 'brilliant', 'scientist', 'edward', 'brake', 'wellington', 'meffert', 'george', 'who', 'looks', 'like', 'a', 'demented', 'felt', 'clown', 'with', 'green', 'wool', 'for', 'hair', 'is', 'the', 'artificially', 'intelligent', 'interface', 'for', 'an', 'advanced', 'computer', 'system', 'that', 'operates', 'a', 'revolutionary', 'device', 'a', 'silver', 'sphere', 'about', 'the', 'size', 'of', 'a', 'golf', 'ball', 'that', 'when', 'ingested', 'can', 'reverse', 'character', 'disorders', \"edward's\", 'personality', 'altering', 'experiments', 'have', 'been', 'successful', 'on', 'lab', 'animals', 'but', 'the', 'cautious', 'scientist', 'is', 'reluctant', 'to', 'carry', 'out', 'tests', 'on', 'human', 'subjects', 'fearing', 'that', 'there', 'may', 'still', 'be', 'side', 'effects', 'his', 'evil', 'assistant', 'julie', 'debbie', 'laster', 'however', 'has', 'no', 'such', 'qualms', 'and', 'proceeds', 'to', 'use', 'three', 'beautiful', 'young', 'women', 'as', 'guinea', 'pigs', 'inevitably', 'they', 'all', 'turn', 'into', 'hideous', 'killer', 'mutants', 'with', 'bargain', 'basement', 'special', 'effects', 'a', 'cast', 'totally', 'devoid', 'of', 'talent', 'and', 'a', 'plot', 'that', 'is', 'almost', 'impossible', 'to', 'follow', 'i', 'took', 'notes', 'as', 'i', 'watched', 'the', 'film', 'and', 'even', 'then', 'i', 'am', 'not', 'entirely', 'convinced', 'that', 'my', 'synopsis', 'is', 'accurate', 'nightmare', 'weekend', 'is', 'a', 'complete', 'and', 'utter', 'disaster', 'that', 'not', 'even', 'several', 'soft', 'core', 'sex', 'scenes', 'and', 'a', 'touch', 'of', 'gore', 'can', 'rescue', 'this', 'film', 'also', 'features', 'one', 'of', 'the', 'most', 'irritating', 'characters', 'i', 'have', 'ever', 'seen', 'in', 'a', 'horror', 'movie', 'tony', 'bruce', 'morton', 'a', 'walkman', 'wearing', 'idiot', 'who', 'bops', 'away', 'to', 'crap', '80s', 'music', 'in', 'a', 'manner', 'that', 'makes', 'me', 'look', 'like', 'justin', 'timberlake', 'in', 'comparison', 0])\n",
      " list(['i', 'happened', 'upon', 'this', 'film', 'by', 'accident', 'and', 'really', 'enjoyed', 'timothy', \"busfield's\", 'character', 'is', 'without', 'redeeming', 'qualities', 'and', 'at', 'one', 'point', 'busfield', 'and', 'star', 'meloni', 'ogle', 'women', 'as', 'they', 'pass', 'by', \"meloni's\", 'take', 'on', 'the', 'parade', 'is', 'different', 'from', \"busfield's\", 'janel', 'maloney', 'is', 'terrific', 'she', 'looks', 'very', 'much', 'like', 'tea', 'leone', 'but', 'the', 'major', 'difference', 'here', 'is', 'that', 'janel', 'can', 'actually', 'act', 'some', 'very', 'nice', 'things', 'in', 'this', 'film', 'and', 'well', 'worth', 'your', 'attention', 'when', \"it's\", 'on', 'cable', 1])\n",
      " list(['a', 'young', 'scientist', 'is', 'trying', 'to', 'carry', 'on', 'his', 'dead', \"father's\", 'work', 'on', 'limb', 'regeneration', 'his', 'overbearing', 'mother', 'has', 'convinced', 'him', 'that', 'he', 'murdered', 'his', 'own', 'father', 'and', 'is', 'monitoring', 'his', 'progress', 'for', 'her', 'own', 'evil', 'purposes', 'a', 'young', 'doctor', 'uses', 'reptilian', 'dna', 'he', 'extracts', 'from', 'a', 'large', 'creature', 'and', 'when', 'his', 'arm', 'is', 'conveniently', 'ripped', 'off', 'a', 'few', 'minutes', 'later', 'he', 'injects', 'himself', 'with', 'his', 'formula', 'and', 'grows', 'a', 'new', 'murderous', 'arm', 'admittedly', 'the', 'special', 'effects', 'in', 'severed', 'ties', 'are', 'pretty', 'good', 'and', 'grotesque', 'but', 'the', 'rest', 'of', 'the', 'film', 'is', 'awful', 'the', 'severed', 'arm', 'is', 'behaving', 'like', 'a', 'snake', 'and', 'kills', 'few', 'people', 'big', 'deal', 'the', 'acting', 'is', 'mediocre', 'and', 'the', 'climax', 'is', 'silly', '3', 'out', 'of', '10', 0])]\n"
     ]
    }
   ],
   "source": [
    "#Romdomly shuffle the rows  \n",
    "random.shuffle(t_data)\n",
    "print(\"Training folder Dataset after random shuffling:\\n\")\n",
    "print(t_data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset divided in training and development datasets:\n",
      "\n",
      "Training Dataset top 5 rows:\n",
      "\n",
      "[list(['this', 'movie', 'was', 'the', 'best', 'movie', 'i', 'have', 'ever', 'seen', 'being', 'lds', 'i', 'highly', 'recommend', 'this', 'movie', 'because', 'you', 'are', 'able', 'to', 'feel', 'a', 'more', 'understanding', 'about', 'the', 'life', 'of', 'joseph', 'smith', 'although', 'the', 'movie', 'was', 'not', 'made', 'with', 'highly', 'acclaimed', 'actors', 'it', 'is', 'a', 'remarkable', 'and', 'life', 'changing', 'movie', 'that', 'can', 'be', 'enjoyed', 'and', 'appreciated', 'by', 'everyone', 'i', 'saw', 'this', 'movie', 'with', 'my', 'family', 'and', 'i', 'can', 'bear', 'witness', 'that', 'we', 'have', 'all', 'had', 'a', 'change', 'of', 'heart', 'this', 'movie', 'allows', 'people', 'to', 'really', 'understand', 'how', 'hard', 'the', 'life', 'was', 'for', 'the', 'prophet', 'and', 'how', 'much', 'tribulation', 'he', 'was', 'faced', 'with', 'after', 'i', 'saw', 'this', 'movie', 'there', 'was', 'not', 'a', 'single', 'dry', 'eye', 'in', 'the', 'entire', 'room', 'everyone', 'was', 'touched', 'by', 'what', 'they', 'saw', 'and', 'i', 'have', 'not', 'been', 'the', 'same', 'since', 'i', 'have', 'seen', 'it', 'i', 'highly', 'recommend', 'this', 'movie', 'for', 'everyone', 1])\n",
      " list(['this', 'is', 'an', 'excellent', 'film', 'for', 'female', 'body', 'builder', 'female', 'action', 'fans', 'i', 'think', 'that', 'sue', 'price', 'did', 'a', 'great', 'job', 'in', 'this', 'film', 'series', 'nemesis', '2', '3', '4', 'and', 'proved', 'to', 'be', 'a', 'great', 'fighter', 'she', 'has', 'a', 'very', 'striking', 'appearance', 'and', 'a', 'will', 'of', 'iron', 'to', 'resist', 'the', 'powerful', 'nebula', 'nemesis', '2', 'though', 'not', 'a', 'film', 'of', 'great', 'value', 'and', 'sue', \"price's\", 'acting', 'skills', 'not', 'the', 'best', 'to', 'have', 'met', 'in', 'my', 'life', 'the', 'movie', 'itself', 'was', 'something', 'awesome', 'a', 'priceless', 'gem', 'for', 'fans', 'of', 'female', 'body', 'builder', 'action', 'well', 'some', 'parts', 'of', 'nemesis', '2', 'have', 'been', 'copied', 'by', 'other', 'famous', 'sci', 'fi', 'films', 'such', 'as', 'terminator', 'or', 'predator', 'but', \"that's\", 'not', 'the', 'point', 'the', 'point', 'is', 'that', 'a', 'puyn', 'casted', 'in', 'that', 'film', 'a', 'very', 'talented', 'body', 'builder', 'who', 'put', 'all', 'of', 'her', 'energy', 'and', 'body', 'talent', 'to', 'show', 'us', 'the', 'best', 'she', 'can', 'do', 'i', 'really', 'enjoyed', 'that', 'film', 'and', 'watched', 'with', 'the', 'same', 'enthusiasm', 'nemesis', '3', 'a', 'rather', 'boring', 'sequel', 'and', 'nemesis', '4', 'a', 'much', 'more', 'interesting', 'sequel', 'than', '3', 'what', 'a', 'pity', 'it', \"hasn't\", 'shown', 'yet', 'on', 'dvd', 1])\n",
      " list(['steve', 'carell', 'has', 'made', 'a', 'career', 'out', 'of', 'portraying', 'the', 'slightly', 'odd', 'straight', 'guy', 'first', 'on', \"'the\", 'daily', \"show'\", 'and', 'then', 'in', 'various', 'supporting', 'roles', 'in', 'virgin', 'carell', 'has', 'found', 'a', 'clever', 'and', 'hilarious', 'script', 'that', 'perfectly', 'capitalizes', 'on', 'his', 'strengths', 'carell', 'plays', 'andy', 'stitzer', 'a', 'middle', 'aged', 'man', 'living', 'a', 'quiet', 'lonely', 'life', 'andy', 'is', 'a', 'little', 'odd', 'but', 'in', 'an', 'awkward', 'nice', 'guy', 'sort', 'of', 'way', 'one', 'night', 'while', 'socializing', 'with', 'his', 'co', 'workers', 'for', 'the', 'first', 'time', 'andy', 'accidentally', 'reveals', 'that', 'he', 'is', 'a', 'virgin', 'his', 'co', 'workers', 'david', 'paul', 'rudd', 'jay', 'romany', 'malco', 'and', 'cal', 'seth', 'rogen', 'initially', 'tease', 'andy', 'about', 'his', 'situation', 'but', \"it's\", 'clear', 'that', 'all', 'three', 'have', 'a', 'certain', 'respect', 'for', 'the', 'decent', 'human', 'being', 'that', 'andy', 'is', 'and', 'they', 'resolve', 'to', 'help', 'him', 'out', 'by', 'assisting', 'him', 'in', 'ending', 'his', 'virginity', 'and', 'so', 'begins', \"andy's\", 'quest', 'into', 'adulthood', 'andy', 'is', 'the', 'quintessential', 'innocent', 'and', 'the', 'bulk', 'of', 'the', 'humor', 'derives', 'from', 'his', 'naivet', 'to', 'the', 'situations', 'he', 'finds', 'himself', 'in', 'throughout', 'the', 'film', 'some', 'of', 'the', 'humor', 'is', 'crude', 'gross', 'out', 'stuff', 'but', 'most', 'of', 'it', 'is', 'just', 'well', 'done', 'intelligent', 'comedy', 'in', 'addition', 'i', 'found', 'some', 'parts', 'of', 'the', 'film', 'actually', 'pretty', 'touching', 'as', 'andy', 'finds', 'himself', 'developing', 'both', 'romantic', 'relationships', 'and', 'friendships', 'perhaps', 'for', 'the', 'first', 'time', 'in', 'his', 'life', \"i'm\", 'not', 'trying', 'to', 'portray', 'the', 'movie', 'as', 'a', 'love', 'story', 'or', 'a', 'drama', \"it's\", 'a', 'rolling', 'in', 'your', 'seats', 'comedy', 'still', 'every', 'good', 'comedy', 'i', 'have', 'ever', 'seen', 'contains', 'enough', 'heart', 'for', 'you', 'to', 'care', 'about', 'the', 'characters', 'a', 'good', 'comparison', 'would', 'be', \"'the\", 'wedding', \"crashers'\", 'from', 'earlier', 'this', 'summer', 'virgin', 'has', 'a', 'similar', 'humor', 'but', 'is', 'perhaps', 'a', 'bit', 'more', 'vulgar', 'in', 'some', 'of', 'its', 'jokes', 'i', 'particularly', 'loved', 'the', 'ending', 'of', 'the', 'film', 'which', 'i', 'thought', 'was', 'a', 'perfect', 'way', 'to', 'end', 'the', 'flick', 'without', 'giving', 'anything', 'away', 'it', 'reminded', 'me', 'of', \"'something\", 'about', \"mary'\", 'very', 'light', 'and', 'fun', 'it', 'leaves', 'you', 'laughing', 'and', 'smiling', 'which', 'is', 'exactly', 'how', 'you', 'should', 'feel', 'when', 'you', 'finish', 'a', 'comedy', 'i', 'would', 'highly', 'recommend', 1])\n",
      " list(['the', 'film', 'is', 'bad', 'there', 'is', 'no', 'other', 'way', 'to', 'say', 'it', 'the', 'story', 'is', 'weak', 'and', 'outdated', 'especially', 'for', 'this', 'country', 'i', \"don't\", 'think', 'most', 'people', 'know', 'what', 'a', 'walker', 'is', 'or', 'will', 'really', 'care', 'i', 'felt', 'as', 'if', 'i', 'was', 'watching', 'a', 'movie', 'from', 'the', \"70's\", 'the', 'subject', 'was', 'just', 'not', 'believable', 'for', 'the', 'year', '2007', 'even', 'being', 'set', 'in', 'dc', 'i', 'think', 'this', 'rang', 'true', 'for', 'everyone', 'else', 'who', 'watched', 'it', 'too', 'as', 'the', 'applause', 'were', 'low', 'and', 'quick', 'at', 'the', 'end', 'most', \"didn't\", 'stay', 'for', 'the', 'q', 'a', 'either', 'i', \"don't\", 'think', 'schrader', 'really', 'thought', 'the', 'film', 'out', 'ahead', 'of', 'time', 'many', 'of', 'the', 'scenes', 'seemed', 'to', 'be', 'cut', 'short', 'as', 'if', 'they', 'were', 'never', 'finished', 'or', 'he', 'just', \"didn't\", 'know', 'how', 'to', 'finish', 'them', 'he', 'jumped', 'from', 'one', 'scene', 'to', 'the', 'next', 'and', 'you', 'had', 'to', 'try', 'and', 'figure', 'out', 'or', 'guess', 'what', 'was', 'going', 'on', 'i', 'really', \"didn't\", 'get', \"woody's\", 'carter', 'private', 'life', 'or', 'boyfriend', 'either', 'what', 'were', 'all', 'the', 'artistic', 'male', 'bondage', 'and', 'torture', 'pictures', 'from', 'iraq', 'prisons', 'about', 'what', 'was', 'he', 'thinking', 'i', 'think', 'it', 'was', 'his', 'very', 'poor', 'attempt', 'at', 'trying', 'to', 'create', 'this', 'dark', 'private', 'subculture', 'life', 'for', \"woody's\", 'character', 'car', 'it', \"didn't\", 'work', 'it', \"didn't\", 'even', 'seem', 'to', 'make', 'sense', 'really', 'the', 'only', 'good', 'thing', 'about', 'this', 'film', 'was', 'woody', 'harrelson', 'he', 'played', 'his', 'character', 'car', 'flawlessly', 'you', 'really', 'did', 'get', 'a', 'great', 'sense', 'of', 'what', 'a', 'walker', 'may', 'have', 'been', 'like', 'say', 'twenty', 'years', 'ago', 'he', 'was', 'great', 'and', 'most', 'likely', 'will', 'never', 'get', 'recognized', 'for', 'it', 'as', 'for', 'lauren', 'lily', 'and', 'kristin', 'boring', \"don't\", 'see', 'it', 'it', 'is', 'painful', 'unless', 'you', 'are', 'a', 'true', 'harrelson', 'fan', 0])\n",
      " list(['this', 'film', 'is', 'overblown', 'predictable', 'pretentious', 'and', 'hollow', 'to', 'its', 'core', 'the', 'settings', 'are', 'faithful', 'to', 'the', 'era', 'but', 'self', 'conscious', 'in', 'their', 'magnification', 'by', 'prolonged', 'exposure', 'the', 'lingering', 'over', 'artifacts', 'stops', 'the', 'action', 'and', 'cloys', 'almost', 'as', 'much', 'as', 'the', 'empty', 'dialogue', 'tom', 'hanks', 'seems', 'to', 'be', 'sleepwalking', 'much', 'as', 'bruce', 'willis', 'did', 'in', \"hart's\", 'war', 'tom', 'you', \"can't\", 'give', 'depth', 'to', 'a', 'character', 'simply', 'by', 'making', 'your', 'face', 'blank', 'the', 'content', 'did', 'not', 'warrant', 'the', 'histrionic', 'acting', 'by', 'paul', 'newman', 'this', 'is', 'a', 'dud', 'wrapped', 'in', 'an', 'atomic', 'bomb', 'casing', 0])]\n",
      "\n",
      "Development Dataset top 5 rows:\n",
      "\n",
      "[list(['a', 'great', 'bugs', 'bunny', 'cartoon', 'from', 'the', 'earlier', 'years', 'has', 'bugs', 'as', 'a', 'performer', 'in', 'an', 'window', 'display', 'at', 'a', 'local', 'department', 'store', 'after', \"he's\", 'done', 'for', 'the', 'day', 'the', 'manager', 'comes', 'in', 'to', 'tell', 'him', 'that', \"he'll\", 'be', 'transferring', 'soon', 'bugs', 'is', 'happy', 'to', 'oblige', 'into', 'he', 'figures', 'out', 'that', 'the', 'new', 'job', 'is', 'in', 'taxidermy', 'and', 'that', 'taxidermy', 'has', 'to', 'do', 'with', 'stuffing', 'animals', 'animals', 'like', 'say', 'a', 'certain', 'rabbit', 'this', 'causes', 'a', 'battle', 'of', 'wits', 'between', 'the', 'rascally', 'rabbit', 'and', 'his', 'now', 'former', 'employer', 'i', 'found', 'this', 'short', 'to', 'be', 'delightful', 'and', 'definitely', 'one', 'of', 'the', 'better', 'ones', 'of', 'the', 'early', \"1940's\", 'it', 'still', 'remains', 'as', 'funny', 'nearly', '60', 'years', 'later', 'this', 'animated', 'short', 'can', 'be', 'seen', 'on', 'disc', '1', 'of', 'the', 'looney', 'tunes', 'golden', 'collection', 'volume', '2', 'my', 'grade', 'a', 1])\n",
      " list(['a', 'favourite', 'of', 'mine', 'this', 'movie', 'tells', 'of', 'two', 'feuding', 'new', 'york', 'characters', 'steve', 'brodie', 'raft', 'and', 'chuck', 'connors', 'beery', 'who', 'both', 'strive', 'to', 'be', 'the', 'main', 'guy', 'in', 'the', 'bowery', 'in', 'the', 'late', 'nineteenth', 'century', 'brodie', '1863', '1901', 'and', 'connors', '1852', '1913', 'were', 'real', 'people', 'though', 'this', 'is', 'a', 'heavily', 'fictionalized', 'account', 'of', 'their', 'antics', 'based', 'on', 'a', 'play', \"brodie's\", 'legendary', 'did', 'he', 'do', 'it', \"it's\", 'still', 'a', 'cause', 'of', 'argument', 'jump', 'from', 'the', 'brooklyn', 'bridge', '1886', 'for', 'which', 'he', 'became', 'famous', 'is', 'shown', 'here', 'as', 'happening', 'around', 'the', 'same', 'time', 'as', 'the', 'spanish', 'american', 'war', '1898', 'director', 'walsh', 'clearly', 'had', 'a', 'great', 'affection', 'for', 'the', 'period', 'so', 'beautifully', 'recreated', 'here', 'and', 'it', 'includes', 'a', 'wild', 'rumbustious', 'ragtime', 'number', 'from', 'saloon', 'singer', 'trixie', 'odbray', 'a', 'young', 'pert', 'kelton', 'raft', 'is', 'at', 'his', 'slickest', 'as', 'brodie', 'and', 'beery', 'shows', 'again', 'what', 'a', 'clever', 'actor', 'he', 'was', 'as', 'tough', 'big', 'hearted', 'and', 'at', 'times', 'quite', 'touching', 'connors', 'pretty', 'fay', 'wray', 'is', 'the', 'love', 'interest', 'both', 'the', 'boys', 'are', 'pursuing', 'full', 'of', 'life', 'and', 'energy', 'the', 'bowery', 'moves', 'at', 'a', 'fast', 'pace', 'unlike', 'many', 'early', 'talkies', 'it', 'is', 'not', 'an', 'easy', 'movie', 'to', 'find', 'but', 'is', 'well', 'worth', 'looking', 'out', 'for', 1])\n",
      " list(['yes', 'this', 'gets', 'the', 'full', 'ten', 'stars', \"it's\", 'plain', 'as', 'day', 'that', 'this', 'fill', 'is', 'genius', 'the', 'universe', 'sent', 'trent', 'harris', 'a', 'young', 'wonderfully', 'strange', 'man', 'one', 'day', 'and', 'harris', 'caught', 'him', 'on', 'tape', 'in', 'all', 'that', 'true', 'misfit', 'glory', 'that', 'you', 'just', \"can't\", 'fake', 'too', 'bad', 'it', 'ended', 'in', 'tragedy', 'for', 'the', 'young', 'man', 'if', 'only', 'an', 'alternate', 'ending', 'could', 'be', 'written', 'for', 'that', \"fellow's\", 'story', 'the', 'other', 'two', 'steps', 'in', 'the', 'trilogy', 'do', 'retell', 'the', 'story', 'with', 'sean', 'penn', 'and', 'crispin', 'glover', 'in', 'the', 'roles', 'of', 'the', 'young', 'men', 'respectively', 'the', 'world', 'is', 'expanded', 'upon', 'and', 'the', 'strangeness', 'is', 'contextualized', 'by', 'the', 'retelling', 'giving', 'us', 'a', 'broader', 'glimpse', 'into', 'growing', 'up', 'weird', 'in', 'vanilla', 'america', 'recommended', 'for', 'anyone', 'and', 'everyone', 1])\n",
      " list([\"here's\", 'another', 'movie', 'that', 'should', 'be', 'loaded', 'into', 'a', 'satellite', 'fired', 'into', 'space', 'and', 'pointed', 'in', 'the', 'direction', 'of', 'the', 'galaxy', 'andromeda', 'to', 'show', 'distant', 'possible', 'civilizations', 'the', 'best', 'of', 'humanity', 'this', 'movie', 'is', 'so', 'endearingly', 'stupid', 'and', 'revealingly', 'honest', 'in', 'being', 'little', 'more', 'than', 'a', 'rip', 'off', 'of', 'the', 'already', 'bad', 'movie', 'classic', 'king', 'kong', 'from', '1976', 'that', 'it', 'not', 'only', 'manages', 'to', 'upstage', 'that', 'film', 'in', 'terms', 'of', 'sheer', 'belly', 'laugh', 'idiotic', 'goofiness', 'but', 'successfully', 'predicted', 'much', 'of', 'peter', \"jackson's\", 'miserable', '2005', 'computer', 'cartoon', 'bearing', 'the', 'same', 'name', 'as', 'far', 'as', 'a', 'romance', 'between', 'the', 'giant', 'here', 'a', 'yeti', 'and', 'a', 'gorgeous', 'human', 'female', 'antonellina', 'interlenghi', 'of', 'umberto', \"lenzi's\", 'city', 'of', 'the', 'living', 'dead', 'who', 'is', 'very', 'easy', 'on', 'the', 'eyes', 'the', 'film', 'was', 'made', 'for', 'kids', 'so', 'aside', 'from', 'some', 'innuendo', 'over', 'fish', 'bones', 'and', 'a', 'bizarre', 'nipple', 'tweak', 'to', 'say', 'goodbye', 'you', 'can', 'forget', 'about', 'sex', 'the', 'yeti', 'even', 'has', 'a', 'sort', 'of', 'giant', 'jock', 'strap', 'to', 'cover', 'up', 'his', 'monstrous', 'package', 'the', 'result', 'being', 'even', 'more', 'amusing', 'than', 'anatomical', 'correctness', 'but', 'as', 'a', 'trade', 'off', 'you', 'do', 'get', 'a', 'wacky', 'old', 'scientist', 'two', 'inquisitive', 'kids', 'tony', 'kendall', 'in', 'a', 'rare', 'turn', 'as', 'a', 'duplicitous', 'bastard', 'of', 'a', 'villain', 'a', 'helpful', 'intelligent', 'collie', 'dog', 'who', 'gets', 'to', 'have', 'her', 'own', 'adventure', 'dog', 'adventure', 'movies', 'were', 'big', 'in', 'europe', 'for', 'a', 'while', 'and', 'of', 'course', 'emerges', 'as', 'the', 'hero', 'at', 'the', 'end', 'for', 'saving', 'the', 'yeti', 'who', 'turns', 'out', 'to', 'be', 'the', 'good', 'guy', 'glorious', 'stuff', 'like', 'front', 'end', 'loaders', 'decorated', 'to', 'look', 'like', 'giant', 'ape', 'hands', 'a', 'monster', \"who's\", 'size', 'literally', 'changes', 'scale', 'from', 'shot', 'to', 'shot', 'some', 'inappropriately', 'horrible', 'deaths', 'that', 'will', 'make', 'the', 'carnage', 'in', 'godzilla', 'vs', 'the', 'smog', 'monster', 'look', 'tame', 'by', 'comparison', 'crowd', 'reaction', 'shots', 'a', 'plenty', 'made', 'up', 'of', 'either', 'spanish', 'italian', 'or', 'canadian', 'extras', 'depending', 'upon', 'scene', 'you', 'can', 'sort', 'of', 'tell', 'where', 'they', 'were', 'shooting', 'from', 'how', 'the', 'extras', 'are', 'dressed', 'and', 'some', 'of', 'the', 'most', 'enthusiastically', 'staged', 'but', 'inept', 'special', 'effects', 'work', 'ever', 'in', 'a', 'giant', 'monkey', 'movie', \"it's\", 'here', 'that', 'the', 'film', 'won', 'me', 'over', \"it's\", 'enthusiasm', 'just', 'for', 'being', 'made', 'frank', 'kramer', 'is', 'actually', 'the', 'same', 'gianfranco', 'parolini', 'who', 'brought', 'the', 'world', 'sartana', 'in', '1968', 'and', \"god's\", 'gun', 'the', 'year', 'before', 'this', 'was', 'a', 'very', 'important', 'director', 'in', 'the', 'spaghetti', 'western', 'and', 'action', 'adventure', 'genre', 'film', 'scene', 'from', 'the', \"1960's\", \"1970's\", 'and', 'by', 'the', 'time', 'of', 'yeti', 'he', 'was', 'probably', 'delighted', 'to', 'get', 'the', 'work', 'i', 'would', 'say', 'that', 'this', 'is', 'his', 'most', 'adventuresome', 'movie', 'ever', 'or', 'rather', 'the', 'one', 'he', 'took', 'the', 'most', 'chances', 'with', 'and', 'may', 'have', 'felt', 'more', 'comfortable', 'taking', 'those', 'chances', 'with', 'the', 'film', 'aimed', 'at', 'kids', 'families', 'the', 'movie', 'has', 'a', 'kind', 'of', 'reckless', 'abandon', 'to', 'the', 'way', 'it', 'was', 'made', 'that', 'renders', 'the', 'technical', 'errors', 'or', 'inconsistencies', 'totally', 'meaningless', 'or', 'rather', 'they', 'are', 'part', 'of', 'the', 'fun', 'and', 'if', 'the', 'movie', 'had', 'been', 'played', 'seriously', 'it', \"wouldn't\", 'have', 'worked', 'which', 'is', 'exactly', 'why', 'peter', \"jackson's\", 'movie', 'sucked', 'he', 'forgot', 'to', 'have', 'fun', 'with', 'the', 'material', 'and', 'let', 'it', 'dictate', 'the', 'outcome', 'using', 'his', 'army', 'of', 'stupid', 'power', 'macintosh', 'pod', 'people', 'animators', 'and', 'with', 'all', \"it's\", 'faults', 'clunkiness', \"kramer's\", 'yeti', 'is', 'actually', 'closer', 'to', 'the', 'spirit', 'of', 'why', 'we', 'watch', 'movies', 'like', 'this', 'which', 'is', 'partly', 'to', 'see', 'actors', 'in', 'ape', 'suits', 'tearing', 'apart', 'miniature', 'sets', 'on', 'sound', 'stages', 'not', 'seamlessly', 'animated', 'vapid', 'hours', 'of', 'nothing', 'other', 'than', 'hard', 'drive', 'space', \"i'd\", 'rank', 'this', 'up', 'there', 'with', 'king', 'kong', 'versus', 'godzilla', 'and', 'it', 'curse', 'of', 'the', 'great', 'golem', 'as', 'one', 'of', 'the', 'most', 'enjoyably', 'improbable', 'giant', 'rampaging', 'monster', 'movies', 'ever', 'because', 'the', 'movie', 'looks', 'so', 'fake', 'you', 'can', 'get', 'over', 'the', 'story', 'and', 'just', 'have', 'fun', 'watching', 'stuff', 'get', 'wrecked', 'trampled', 'tossed', 'about', 'and', 'smashed', 'knowing', 'that', 'and', 'armed', 'with', 'a', 'fertile', 'energetic', 'enthusiasm', 'for', 'having', 'the', 'chance', 'to', 'make', 'the', 'movie', 'parolini', 'pulled', 'out', 'all', 'the', 'stops', 'and', 'delivers', 'a', 'full', 'bodied', 'adventure', 'that', 'might', 'get', 'a', 'bit', 'rough', 'for', 'some', 'of', 'the', 'small', 'tykes', 'but', 'is', 'the', 'first', 'movie', 'i', 'will', 'ever', 'share', 'with', 'the', 'grandkids', 'someday', 'when', 'their', 'stupid', 'parents', 'leave', 'them', 'with', 'me', 'for', 'a', 'weekend', 'this', 'is', 'stuff', 'for', 'the', 'ages', 'and', 'one', 'of', 'the', 'most', 'telling', 'expressions', 'of', 'humanity', 'to', 'ever', 'be', 'committed', 'to', 'celluloid', '10', '10', \"it's\", 'about', 'ten', 'minutes', 'too', 'long', 'but', 'who', 'cares', 'you', 'only', 'come', 'around', 'once', 'and', \"i'd\", 'rather', 'go', 'out', 'with', 'a', 'smile', 'on', 'my', 'face', 1])\n",
      " list(['castle', 'of', \"blood'\", 'aka', 'castle', 'of', \"terror'\", 'is', 'a', 'well', 'crafted', 'surprisingly', 'spooky', 'entry', 'from', 'italian', 'director', 'anthony', 'dawson', 'exquisite', 'black', 'and', 'white', 'cinematography', 'flawless', 'dubbing', 'superb', 'casting', 'fairly', 'logical', 'scripting', 'deliberate', 'pacing', 'and', 'a', 'surprise', 'though', 'totally', 'appropriate', 'ending', 'set', 'this', 'one', 'apart', 'only', 'the', 'films', 'sometimes', 'hokey', 'music', 'and', 'the', 'rather', 'abrupt', 'love', 'at', 'first', \"sight'\", 'between', 'elizabeth', 'barbara', 'steele', 'and', 'alan', 'georges', 'rivi', 're', 'mar', 'an', 'otherwise', 'surprisingly', 'entertaining', 'movie', 'while', 'visiting', 'england', 'edgar', 'allan', 'poe', 'sits', 'in', 'a', 'pub', 'telling', 'one', 'of', 'his', 'ghostly', 'stories', 'to', 'count', 'blackwood', 'recognizing', 'the', 'great', 'writer', 'alan', 'a', 'young', 'news', 'reporter', 'requests', 'an', 'interview', 'with', 'poe', 'during', 'the', 'course', 'of', 'the', 'conversation', 'poe', 'reveals', 'that', 'all', 'of', 'his', 'stories', 'are', 'true', 'incredulous', 'alan', 'expresses', 'his', 'skepticism', 'about', 'life', 'after', 'death', 'count', 'blackwood', 'offers', 'to', 'bet', 'alan', '100', 'pounds', 'that', 'he', 'cannot', 'survive', 'this', 'night', 'in', \"blackwood's\", 'castle', 'a', 'night', 'following', 'halloween', 'when', 'the', 'dead', 'walk', 'alan', 'cannot', 'afford', 'the', 'bet', 'so', 'he', 'bets', 'his', 'life', 'for', 'a', '10', 'pound', 'wager', 'unlike', 'mario', \"bava's\", 'overpraised', 'black', 'sunday', \"'\", 'aka', 'the', 'mask', 'of', \"satan'\", 'castle', 'of', \"blood'\", 'is', 'fairly', 'restrained', 'making', 'the', 'few', 'moments', 'of', 'violence', 'even', 'more', 'dreadful', 'especially', 'surprising', 'from', 'a', 'director', 'usually', 'associated', 'with', 'those', 'terrible', 'italian', 'space', 'movies', 'from', 'the', '60s', \"it's\", 'a', 'pity', 'the', 'only', 'version', 'of', 'this', 'film', \"i've\", 'found', 'is', 'badly', 'deteriorated', 'and', 'recorded', 'pan', 'and', 'scan', 'version', 'even', 'so', 'it', 'is', 'well', 'worth', 'seeing', 'and', 'cries', 'out', 'for', 'a', 'modern', 'remake', 'perhaps', 'with', 'christina', 'ricci', 'or', 'jennifer', 'love', 'hewitt', 'in', 'the', 'role', 'of', 'elizabeth', 'watch', 'it', 'and', 'enjoy', 'a', 'film', 'that', 'compares', 'well', 'with', 'robert', \"wise's\", 'the', \"haunting'\", 1])]\n"
     ]
    }
   ],
   "source": [
    "#Split the dataset in the ratio of 80:20 training and developing dataset\n",
    "total_data=np.shape(t_data)[0]\n",
    "first_portion=80\n",
    "train_dataset=t_data[0:(int)((first_portion*total_data)/100)]\n",
    "dev_dataset=t_data[(int)((first_portion*total_data)/100)+1:]  \n",
    "print(\"Dataset divided in training and development datasets:\\n\") \n",
    "print(\"Training Dataset top 5 rows:\\n\") \n",
    "print(train_dataset[0:5]) \n",
    "print(\"\\nDevelopment Dataset top 5 rows:\\n\") \n",
    "print(dev_dataset[0:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing folder Dataset after random shuffling:\n",
      "\n",
      "[list(['i', 'was', 'once', 'a', 'big', 'olsen', 'fan', 'i', 'received', 'this', 'movie', 'when', 'i', 'was', 'six', 'and', 'watched', 'it', 'almost', 'nonstop', 'until', 'i', 'was', 'nine', 'then', 'it', 'lay', 'on', 'my', 'shelf', 'gathering', 'dust', 'until', 'yesterday', 'i', 'was', 'left', 'speechless', 'mary', 'kate', 'and', 'ashley', 'play', 'allie', 'and', 'mel', 'two', 'twelve', 'year', 'olds', 'who', 'are', 'sent', 'to', 'spend', 'spring', 'break', 'in', 'paris', 'with', 'their', 'ambassador', 'grandfather', 'along', 'the', 'way', 'they', 'meet', 'as', 'one', 'might', 'expect', 'two', 'cute', 'french', 'boys', 'who', 'show', 'them', 'the', 'more', 'fun', 'side', 'to', 'paris', 'i', 'guess', 'the', 'two', 'boys', 'were', 'okay', 'fake', 'french', 'accents', 'aside', 'the', 'plot', 'is', 'predictable', 'and', 'the', 'humour', 'is', 'shallow', 'and', 'corny', 'mary', 'kate', 'and', 'ashley', 'play', 'two', 'shallow', 'girls', 'with', 'too', 'much', 'make', 'up', 'on', 'their', 'face', \"don't\", 'watch', 'this', 'movie', 'if', \"you're\", 'not', 'into', 'the', 'olsen', 'twins', 'or', 'family', 'movies', 0])\n",
      " list(['alan', 'rickman', 'emma', 'thompson', 'give', 'good', 'performances', 'with', 'southern', 'new', 'orleans', 'accents', 'in', 'this', 'detective', 'flick', \"it's\", 'worth', 'seeing', 'for', 'their', 'scenes', 'and', \"rickman's\", 'scene', 'with', 'hal', 'holbrook', 'these', 'three', 'actors', 'mannage', 'to', 'entertain', 'us', 'no', 'matter', 'what', 'the', 'movie', 'it', 'seems', 'the', 'plot', 'for', 'the', 'movie', 'shows', 'potential', 'but', 'one', 'gets', 'the', 'impression', 'in', 'watching', 'the', 'film', 'that', 'it', 'was', 'not', 'pulled', 'off', 'as', 'well', 'as', 'it', 'could', 'have', 'been', 'the', 'fact', 'that', 'it', 'is', 'cluttered', 'by', 'a', 'rather', 'uninteresting', 'subplot', 'and', 'mostly', 'uninteresting', 'kidnappers', 'really', 'muddles', 'things', 'the', 'movie', 'is', 'worth', 'a', 'view', 'if', 'for', 'nothing', 'more', 'than', 'entertaining', 'performances', 'by', 'rickman', 'thompson', 'and', 'holbrook', 0])\n",
      " list(['an', 'opera', 'diva', 'has', 'an', 'accident', 'which', 'leaves', 'the', 'door', 'open', 'for', 'her', 'understudy', 'to', 'take', 'over', 'the', 'role', 'betty', 'marsillach', 'is', 'now', 'the', 'star', 'of', 'mac', 'beth', 'but', 'someone', 'hiding', 'in', 'the', 'trenches', 'has', 'an', 'opera', 'of', 'his', 'own', 'planned', 'out', 'he', 'gets', 'his', 'kicks', 'out', 'of', 'tying', 'betty', 'up', 'putting', 'needles', 'under', 'her', 'eyes', 'so', 'she', 'cant', 'close', 'them', 'and', 'murdering', 'members', 'of', 'the', 'opera', 'company', 'before', 'her', 'very', 'eyes', 'opera', 'is', 'certainly', 'one', 'of', \"argento's\", 'more', 'ambitious', 'films', 'like', 'mixing', 'it', 'up', 'with', \"shakesphere's\", 'macbeth', 'there', 'is', 'of', 'course', 'the', 'fact', 'that', 'the', 'opera', 'performed', 'in', 'the', 'film', 'is', 'giuseppe', \"verdi's\", 'version', 'of', 'macbeth', 'but', 'also', 'argento', 'just', 'like', 'shakespeare', 'uses', 'ravens', 'as', 'an', 'omen', 'of', 'death', 'and', 'misfortune', 'and', 'like', 'the', 'ravens', 'circling', 'the', 'castle', 'dunsinane', 'foreboding', 'the', 'demise', 'of', 'the', 'scheming', 'macbeth', 'the', 'ravens', 'in', 'opera', 'play', 'a', 'key', 'part', 'in', 'the', 'downfall', 'of', 'the', 'killer', 'furthermore', 'just', 'like', 'in', 'the', 'old', 'play', 'the', 'murderer', 'acts', 'on', 'the', 'exhortation', 'of', 'his', 'lover', 'but', 'i', \"don't\", 'want', 'to', 'go', 'as', 'far', 'as', 'saying', 'opera', 'is', 'intended', 'to', 'be', 'a', 'remake', 'of', 'the', 'either', 'the', 'phantom', 'of', 'the', 'opera', 'or', 'macbeth', 'the', 'similarities', 'are', 'far', 'too', 'subtle', \"it's\", 'just', 'a', 'typical', 'argento', 'masterstroke', 'and', 'with', 'it', 'he', 'gives', 'this', 'otherwise', 'quite', 'basic', 'thriller', 'a', 'vivid', 'hue', 'of', 'gothic', 'mystique', 'although', 'this', 'movie', 'does', 'have', 'it', 'downsides', 'like', 'the', 'heavl', 'metal', 'soundtrack', 'just', \"doesn't\", 'fit', 'in', 'with', 'this', 'movie', 'and', 'the', 'final', 'scenes', 'in', 'this', 'movie', 'are', 'a', 'bit', 'strange', 'all', 'in', 'all', 'opera', 'is', 'something', 'of', 'a', 'flawed', 'masterpiece', 'but', 'still', 'good', 1])\n",
      " list(['i', 'always', 'liked', 'listening', 'to', 'buddy', 'holly', 'and', 'felt', 'a', 'real', 'loss', 'when', 'he', 'was', 'killed', 'at', 'a', 'young', 'age', 'in', 'an', 'airplane', 'crash', 'he', \"wasn't\", 'in', 'the', 'old', 'rock', \"'n\", 'roll', 'class', 'of', \"let's\", 'say', 'chuck', 'berry', 'or', 'jerry', 'lee', 'lewis', 'but', 'he', \"wasn't\", 'far', 'behind', 'who', 'knows', 'how', 'big', 'his', 'legacy', 'would', 'have', 'been', 'had', 'he', 'sang', 'for', 'decades', 'almost', 'every', 'single', 'he', 'put', 'out', 'was', 'a', 'hit', 'so', 'i', 'was', 'very', 'pleasantly', 'surprised', 'how', 'good', 'a', 'job', 'gary', 'busey', 'did', 'at', 'playing', 'him', 'and', 'at', 'imitating', 'his', 'singing', 'voice', 'he', 'did', 'buddy', 'proud', 'as', 'were', 'the', 'actors', 'don', 'stroud', 'and', 'charles', 'martin', 'smith', 'who', 'played', \"holly's\", 'backup', 'group', 'the', 'crickets', 'music', 'wise', 'there', 'are', 'some', 'of', \"holly's\", 'better', 'known', 'songs', 'in', 'the', 'beginning', 'of', 'the', 'film', 'and', 'its', 'really', 'good', 'with', 'a', 'strong', 'finish', 'at', 'the', 'end', 'as', 'holly', 'and', 'the', 'boys', 'are', 'shown', 'in', 'iowa', 'in', 'their', 'last', 'concert', 'ever', 'busey', 'not', 'only', 'sings', 'like', 'holly', \"he's\", 'a', 'dead', 'ringer', 'for', 'him', 'in', 'the', 'looks', 'department', 'some', 'thing', 'was', 'the', \"actor''s\", 'best', 'performance', 'ever', 'and', 'you', 'get', 'no', 'argument', 'from', 'me', \"i'm\", 'also', 'glad', 'they', 'ended', 'the', 'film', 'on', 'an', 'upbeat', 'note', 'with', 'that', 'iowa', 'concert', 'instead', 'of', 'dwelling', 'on', 'his', 'tragic', 'accident', 'the', 'ending', 'could', 'have', 'been', 'a', 'real', 'downer', 'but', 'they', \"didn't\", 'let', 'it', 'be', 1])\n",
      " list(['i', 'am', 'really', 'amazed', 'how', 'little', 'fame', 'this', 'film', 'had', 'i', 'think', 'it', 'has', 'to', 'do', 'with', 'distribution', 'companies', 'and', 'etc', \"don't\", 'be', 'idiots', 'if', 'you', 'are', 'looking', 'for', 'a', 'good', 'fun', 'take', 'this', 'movie', 'this', 'is', 'very', 'nice', 'movie', 'to', 'pass', 'few', 'hours', 'with', 'and', 'the', 'music', 'is', 'great', \"it's\", 'about', 'well', 'girls', 'and', 'boys', 'and', 'whats', 'between', 'them', 'with', 'not', 'too', 'much', 'story', 'but', 'not', 'all', 'movies', 'should', 'be', 'pulp', 'fiction', 'should', 'they', \"it's\", 'nice', 'and', 'cute', 'and', 'gives', 'good', 'time', 'the', 'girls', 'are', 'also', 'very', 'good', 'looking', 'and', 'this', 'makes', 'the', 'whole', 'movie', 'even', 'more', 'enjoyable', 'why', 'i', 'gave', 'it', 'only', 'a', '9', 'well', 'the', 'story', 'could', 'be', 'little', 'more', 'convincing', 'from', 'the', 'middle', 'and', 'on', 'in', 'some', 'point', 'you', 'start', 'to', 'see', 'events', 'that', 'are', 'little', 'less', 'reliable', 'small', 'spoiler', 'the', 'baby', 'is', 'crying', 'and', 'the', 'father', 'goes', 'in', 'and', 'tries', 'to', 'relax', 'him', 'now', 'i', 'am', 'not', 'talking', 'about', 'some', 'small', 'cry', 'but', 'no', 'hysteric', 'cry', 'and', '30', 'sec', 'after', 'that', 'the', 'father', 'goes', 'out', 'and', 'baby', 'is', 'sleeping', 'excuse', 'me', 'when', 'and', 'how', 'exactly', 'did', 'you', 'make', 'him', 'calm', 'and', 'sleep', 'and', 'be', 'able', 'to', 'leave', 'his', 'room', 'in', '20', '30', 'seconds', 'but', 'ignore', 'this', 'kind', 'of', 'small', 'picking', 'because', 'the', 'film', 'itself', 'is', 'not', 'docudrama', \"it's\", 'fun', 'and', 'this', 'should', 'be', 'overlooked', 1])\n",
      " list(['this', 'movie', 'from', 'what', 'i', 'remember', 'was', 'such', 'a', 'great', 'movie', 'i', 'watched', 'it', 'on', 'television', 'when', 'i', 'was', '11', 'and', \"couldn't\", 'remember', 'the', 'title', 'of', 'it', 'if', 'i', 'remember', 'correctly', 'i', 'do', 'believe', 'that', 'it', 'was', 'a', 'christmas', 'television', 'movie', 'special', 'one', 'of', 'my', 'friends', 'at', 'work', 'and', 'i', 'were', 'discussing', 'it', 'several', 'years', 'back', 'but', 'neither', 'one', 'of', 'us', 'could', 'remember', 'the', 'title', 'but', 'we', 'did', 'remember', 'almost', 'the', 'entire', 'movie', 'no', 'one', 'else', 'at', 'work', 'remembered', 'ever', 'seeing', 'it', 'thank', 'goodness', 'someone', 'at', 'a', 'tv', 'movie', 'website', 'answered', 'my', 'post', 'now', 'i', 'have', 'the', 'fun', 'job', 'of', 'locating', 'a', 'copy', 'of', 'it', \"it's\", 'amazing', 'what', 'you', 'can', 'remember', 'as', 'a', 'child', 'but', 'this', 'movie', 'definitely', 'remains', 'vividly', 'playing', 'in', 'my', 'head', 'even', 'after', '28', 'years', 'and', 'i', 'do', 'believe', 'i', 'only', 'watched', 'it', 'once', 'maybe', 'it', 'was', 'because', 'i', 'am', 'the', 'oldest', 'sister', 'in', 'my', 'family', 'or', 'maybe', 'because', 'i', 'babysat', 'and', 'worked', 'in', 'day', 'care', 'centers', 'that', 'it', 'stuck', 'with', 'me', 'that', 'long', 'regardless', 'of', 'the', 'real', 'reason', 'it', 'has', 'remained', 'one', 'of', 'the', 'movies', 'that', 'i', 'have', 'been', 'really', 'wanting', 'to', 'watch', 'lately', 'if', 'anyone', 'knows', 'where', 'to', 'watch', 'it', 'online', 'or', 'has', 'a', 'copy', 'please', 'let', 'me', 'know', 'i', 'would', 'so', 'love', 'to', 'see', 'it', 'again', 'thanks', 'so', 'much', 'seriously', 'i', 'tried', 'to', 'post', 'this', 'and', 'it', 'says', 'my', 'comment', \"isn't\", 'long', 'enough', 'so', 'apparently', 'i', 'have', 'to', 'type', 'more', 'did', 'you', 'know', 'that', 'melissa', 'michaelsen', 'is', 'the', 'sister', 'of', 'peter', 'billingsley', 'who', 'starred', 'in', 'a', 'christmas', 'story', 'i', 'know', \"i'm\", 'not', 'the', 'only', 'fan', 'of', 'this', 'movie', 'so', 'if', 'anyone', 'has', 'any', 'idea', 'on', 'where', 'to', 'find', 'this', 'i', 'would', 'greatly', 'appreciate', 'it', 1])\n",
      " list(['if', 'you', 'like', 'silly', 'comedies', 'like', 'airplane', \"you'll\", 'love', 'this', 'movie', \"it's\", 'definitely', 'in', 'the', 'style', 'of', 'airplane', 'and', 'scary', 'movie', 'a', 'fun', 'film', 'it', 'has', 'the', 'strangest', 'cast', 'of', 'characters', 'all', 'in', 'the', 'same', 'movie', 'michael', 'jackson', 'evan', 'marriott', 'joyce', 'giraurd', 'stuart', 'pankin', 'charlie', 'schlater', 'and', 'eric', 'roberts', 'the', 'special', 'effects', 'are', 'hokey', 'but', 'i', 'think', \"they're\", 'supposed', 'to', 'be', 'since', \"it's\", 'a', 'silly', 'comedy', 'there', 'is', 'apparently', 'two', 'versions', 'of', 'the', 'film', 'one', 'at', 'blockbuster', 'and', 'one', 'on', 'the', 'official', 'website', 'misscastaway', 'com', 'the', 'one', 'on', 'the', 'website', 'appears', 'to', 'be', 'a', 'preview', 'release', 'version', 'signed', 'by', 'the', 'director', \"there's\", 'some', 'fun', 'behind', 'the', 'scenes', 'material', 'filmed', 'at', 'neverland', 'with', 'michael', 'jackson', 'as', 'well', 'the', 'movie', 'was', 'filmed', 'in', '2003', 'and', 'says', \"it's\", 'pg', 'rated', 'fun', 'on', 'the', 'box', 1])\n",
      " list([\"'crossing\", 'the', 'bridge', 'the', 'sound', 'of', \"istanbul'\", 'is', 'one', 'of', 'the', 'best', 'music', 'documentaries', 'that', 'i', 'have', 'seen', 'lately', 'and', 'is', 'more', 'than', 'a', 'film', 'about', 'music', 'it', 'is', 'also', 'a', 'musical', 'love', 'declaration', 'about', 'a', 'fabulous', 'city', 'one', 'of', 'the', 'greatest', 'city', 'in', 'europe', 'and', 'the', 'world', 'one', 'of', 'the', 'most', 'important', 'cities', 'for', 'europe', 'history', 'and', 'for', 'islam', 'the', 'city', 'that', 'may', 'bridge', 'in', 'the', 'future', 'europe', 'and', 'the', 'middle', 'east', 'or', 'may', 'signify', 'once', 'again', 'as', 'is', 'already', 'happened', 'in', 'history', 'the', 'precipice', 'between', 'two', 'worlds', 'then', 'there', 'is', 'the', 'music', 'the', 'interesting', 'approach', 'that', 'the', 'film', 'takes', 'with', 'regard', 'to', 'music', 'is', 'that', 'it', 'starts', 'from', 'modern', 'music', 'and', 'we', 'hear', 'a', 'lot', 'of', 'good', 'rock', 'and', 'rap', 'in', 'the', 'first', 'third', 'of', 'the', 'film', 'an', 'then', 'like', 'a', 'backwards', 'move', 'in', 'time', 'the', 'soundtrack', 'takes', 'us', 'to', 'the', 'roots', 'to', 'turkish', 'traditional', 'music', 'to', 'commercial', 'romances', 'and', 'to', 'the', 'exotic', 'instruments', 'that', 'are', 'basic', 'elements', 'in', 'the', 'landscape', 'of', 'turkish', 'music', 'in', 'such', 'a', 'complex', 'and', 'conflict', 'ridden', 'country', 'as', 'turkey', 'is', 'the', 'film', 'does', 'not', 'avoid', 'some', 'of', 'the', 'political', 'aspects', 'like', 'censorship', 'introduced', 'by', 'the', 'military', 'rule', 'in', 'the', '80s', 'or', 'the', 'relevance', 'of', 'the', 'songs', 'of', 'the', 'minorities', 'especially', 'the', 'kurdish', 'one', 'one', 'of', 'the', 'best', 'musical', 'moments', 'is', 'actually', 'provided', 'by', 'a', 'kurdish', 'singer', 'with', 'a', 'fantastic', 'voice', 'singing', 'in', 'a', 'cathedral', 'shaped', 'hamam', 'turkish', 'bath', 'one', 'gets', 'to', 'love', 'the', 'city', 'and', 'its', 'music', 'by', 'the', 'end', 'of', 'the', 'viewing', 'and', 'hearing', 'of', 'this', 'film', 'i', 'have', 'never', 'been', 'to', 'istanbul', 'but', 'after', 'having', 'seen', 'this', 'film', 'i', 'am', 'sure', 'that', 'i', 'want', 'to', 'visit', 'this', 'place', 'soon', 1])\n",
      " list(['a', 'strange', 'relationship', 'between', 'a', 'middle', 'aged', 'woman', 'and', 'a', 'transsexual', 'who', 'gonna', 'be', 'a', 'woman', 'soon', 'charlotte', 'and', 'venorica', 'both', 'trapped', 'by', 'their', 'inanimate', 'lives', 'and', \"don't\", 'know', 'how', 'to', 'get', 'out', 'of', 'them', 'charlotte', 'is', 'an', 'owner', 'of', 'a', 'beauty', 'clinic', 'she', 'has', 'broken', 'up', 'with', 'her', 'aggressive', 'ex', 'husband', 'moved', 'into', 'an', 'apartment', 'alone', 'with', 'all', 'the', 'furniture', 'packed', 'except', 'her', 'big', 'bed', 'veronica', 'lives', 'downstairs', 'with', 'her', 'poor', 'dog', \"she's\", 'sensitive', 'and', 'desperately', 'bothered', 'by', 'her', \"mother's\", 'visiting', 'and', 'the', 'bad', 'relationship', 'with', 'her', 'dad', 'her', 'only', 'hope', 'is', 'that', 'the', 'upcoming', 'transsexual', 'operation', 'will', 'turn', 'her', 'into', 'a', 'real', 'woman', 'and', 'then', 'everything', 'will', 'be', 'fine', 'all', 'she', 'can', 'do', 'now', 'is', 'waiting', 'for', 'an', 'approval', 'certificate', 'then', 'these', 'two', 'individuals', 'meet', 'by', 'chance', 'and', 'gradually', 'they', 'are', 'all', 'involved', 'into', \"other's\", 'lives', 'there', 'are', 'some', 'sparkles', 'between', 'them', 'but', 'no', 'one', 'is', 'brave', 'enough', 'to', 'face', 'the', 'truth', 'because', 'they', 'are', 'not', 'willing', 'to', 'accept', 'the', 'change', 'as', 'most', 'people', 'do', 'eventually', 'the', 'ending', 'is', 'quite', 'satisfying', 'and', 'leaves', 'some', 'imagination', 'for', 'us', 'to', 'think', 'about', 'it', 'the', \"director's\", 'great', 'work', 'gives', 'me', 'an', 'great', 'impression', 'she', 'handles', 'the', 'development', 'of', 'characters', 'very', 'well', 'the', 'emotional', 'atmosphere', 'is', 'quite', 'full', 'and', 'intense', 'also', 'i', 'am', 'so', 'obsessed', 'with', 'the', 'gloomy', 'lights', 'all', 'over', 'the', 'apartment', 'delphic', 'but', 'full', 'of', 'desire', 'two', 'main', 'characters', 'are', 'played', 'by', 'trine', 'dyrholm', 'and', 'david', 'dencik', 'they', 'are', 'amazing', 'in', 'their', 'roles', 'a', 'very', 'impressive', 'performance', 'and', 'the', 'chemical', 'reaction', 'between', 'them', 'is', 'genuine', 'and', 'convincing', 'this', 'swedish', 'indie', 'film', 'is', 'about', 'encountering', 'and', 'change', 'no', 'matter', \"you're\", 'homosexual', 'or', 'heterosexual', 'male', 'or', 'female', 'the', 'oddness', 'of', 'life', 'exists', 'everywhere', 'whenever', 'you', 'fall', 'across', 'it', \"you'll\", 'be', 'hesitate', 'and', 'bewildered', 'but', 'at', 'least', \"don't\", 'be', 'afraid', 'follow', 'your', 'heart', 'and', 'choose', 'the', 'right', 'way', 1])\n",
      " list(['to', 'experience', 'head', 'you', 'really', 'need', 'to', 'understand', 'where', 'the', 'monkees', 'were', 'when', 'they', 'filmed', 'it', 'this', 'was', 'as', 'their', 'series', 'was', 'coming', 'to', 'a', 'close', 'and', 'the', 'group', 'was', 'near', 'break', 'up', 'their', 'inventive', 'and', 'comedic', 'series', 'sort', 'of', 'an', 'american', 'idol', 'of', 'their', 'day', 'took', 'four', 'unknown', 'actors', 'and', 'formed', 'a', 'manufactured', 'supergroup', 'around', 'them', 'this', 'is', 'their', 'take', 'on', 'their', 'manufactured', 'image', 'and', 'status', 'as', 'the', '2nd', 'tier', 'beatles', 'they', 'always', 'felt', 'they', 'were', 'in', 'a', 'box', 'trapped', 'and', 'unable', 'to', 'find', 'credibility', 'despite', 'their', 'talents', 'it', 'is', 'also', 'a', 'hell', 'of', 'a', 'musical', 'trippy', 'inventive', 'i', 'have', 'the', 'soundtrack', 'and', 'full', 'of', 'surprises', 'see', 'it', 'with', 'an', 'open', 'mind', 1])]\n"
     ]
    }
   ],
   "source": [
    "tt_p_dataset=[]\n",
    "tt_n_dataset=[]\n",
    "\n",
    "tt_p_dataset=get_files(\"/Users/deeppatel/aclImdb/test/pos\",1);\n",
    "tt_n_dataset=get_files(\"/Users/deeppatel/aclImdb/test/neg\",0);\n",
    "\n",
    "test_dataset=np.append(tt_p_dataset,tt_n_dataset)\n",
    "\n",
    "random.shuffle(test_dataset)\n",
    "print(\"Testing folder Dataset after random shuffling:\\n\")\n",
    "print(test_dataset[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>B. Build a vocabulary as list. </strong>\n",
    "* [the I happy  ] \n",
    "    * You may omit rare words for example if the occurrence is less than five times\n",
    "* A reverse index as the key value might be handy\n",
    "     * {the: 0, I:1, happy:2 ,  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary list:\n",
      "35113\n",
      "Vocabulary list after removing elements with occurence less than 5 times:\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "vocab_list=[];\n",
    "\n",
    "def build_vocab_list(array):#this function is to array of all vocabs in training\n",
    "    v_list=[]\n",
    "    for i in range(np.shape(array)[0]):\n",
    "        for j in range(len(array[i])-1):#removing last element because it is our solution class 1 or 0.\n",
    "            v_list.append(array[i][j]);\n",
    "    return v_list;       \n",
    "\n",
    "vocab_list=build_vocab_list(train_dataset);\n",
    "        \n",
    "print(\"Vocabulary list:\")        \n",
    "print(len(vocab_list))\n",
    "\n",
    "def remove_element(vocab,array,k):#this function is to remove vocabs in document \n",
    "    for i in range(len(array)-1):\n",
    "        if array[i] not in vocab:\n",
    "            np.delete(array,i)\n",
    "    return array;        \n",
    "#     counted = Counter(array) \n",
    "#     return [r for r in array if counted[r] >= k] \n",
    "\n",
    "k = 5\n",
    "vocab_list=remove_element(vocab_list,train_dataset[0],k)#removing rare words from doc whose frequency is less than 5 in overall vocab list.\n",
    "\n",
    "print(\"Vocabulary list after removing elements with occurence less than 5 times:\") \n",
    "print(len(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocal list to dictionary:\n",
      "[(0, 'this'), (1, 'movie'), (2, 'was'), (3, 'the'), (4, 'best')]\n",
      "Reverse indexing dictory:\n",
      "[('this', 140), ('movie', 141), ('was', 119), ('the', 130), ('best', 4)]\n",
      "New vocalbulary list after reverse indexing:\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "#convert vocab list to dictonary:\n",
    "vocab_dictionary={}\n",
    "def array_to_dict(array):\n",
    "    dictionary={}\n",
    "    for i in range(len(array)):\n",
    "        dictionary[i]=array[i];\n",
    "    return dictionary\n",
    "\n",
    "def dict_to_array(dict):\n",
    "    a=[];\n",
    "    for i in dict:\n",
    "          a.append(i);\n",
    "    return a;\n",
    "\n",
    "vocab_dictionary=array_to_dict(vocab_list);\n",
    "print(\"Vocal list to dictionary:\")\n",
    "print(list(vocab_dictionary.items())[0: 5])\n",
    "\n",
    "#reverse index dictionary:\n",
    "def reverse_index_dictionary(dictionary):\n",
    "    new_dictionary={}\n",
    "    for i in dictionary:\n",
    "        n=dictionary[i];\n",
    "        new_dictionary[n]=i;\n",
    "    return new_dictionary;\n",
    "\n",
    "rev_vocab_dictionary=reverse_index_dictionary(vocab_dictionary);\n",
    "print(\"Reverse indexing dictory:\")\n",
    "print(list(rev_vocab_dictionary.items())[0: 5])\n",
    "\n",
    "new_vocab_list=dict_to_array(rev_vocab_dictionary)\n",
    "print(\"New vocalbulary list after reverse indexing:\")\n",
    "print(len(new_vocab_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Calculate the following probability</strong>\n",
    "* Probability of the occurrence\n",
    "    * P[the] = num of documents containing the / num of all documents\n",
    "* Conditional probability based on the sentiment\n",
    "    * P[the | Positive]  = # of positive documents containing the / num of all positive review documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with count of positive and negative in dataset\n",
      "{1: 72, 0: 88}\n",
      "\n",
      "Document containing the\n",
      "{'the': 158}\n",
      "\n",
      "For testing prop function array:\n",
      "['this', 'movie', 'was', 'the', 'best', 'i', 'have', 'ever', 'seen', 'being']\n",
      "\n",
      "Probability of vocab in testing array vl created above:\n",
      "{'this': 0.9, 'movie': 0.63125, 'was': 0.59375, 'the': 0.9875, 'best': 0.20625, 'i': 0.74375, 'have': 0.60625, 'ever': 0.21875, 'seen': 0.225, 'being': 0.23125}\n",
      "\n",
      "Conditional Probability of vocab in testing array vl created above for positive review:\n",
      "{'this': 0.8611111111111112, 'movie': 0.5833333333333334, 'was': 0.6388888888888888, 'the': 0.9722222222222222, 'best': 0.2222222222222222, 'i': 0.75, 'have': 0.5972222222222222, 'ever': 0.2222222222222222, 'seen': 0.2361111111111111, 'being': 0.19444444444444445}\n"
     ]
    }
   ],
   "source": [
    "#number of positive reviews in documents\n",
    "def count_total_category_reviews(array): #2d array\n",
    "    count_p=0;\n",
    "    count_n=0;\n",
    "    dictionary={}\n",
    "    for i in range(len(array)):\n",
    "        if(int(array[i][len(array[i])-1])==1):\n",
    "            count_p=count_p+1;   \n",
    "        elif(int(array[i][len(array[i])-1])==0):\n",
    "            count_n=count_n+1;\n",
    "    dictionary={1:count_p,0:count_n}      \n",
    "    return dictionary;\n",
    "\n",
    "def count_vocab_in_document(array,vocab):\n",
    "    dictionary={};\n",
    "    count=0;\n",
    "    for i in range(len(array)):\n",
    "        for j in range(len(array[i])-1):#class result is excluded  \n",
    "            if(array[i][j]==vocab):\n",
    "                count=count+1;\n",
    "                break;\n",
    "    dictionary={vocab:count}; \n",
    "    return dictionary;\n",
    "\n",
    "def count_vocab_in_document_review(array,vocab,review):\n",
    "    dictionary={};\n",
    "    count=0;\n",
    "    for i in range(len(array)):\n",
    "        if(int(array[i][len(array[i])-1])==review):         \n",
    "            for j in range(len(array[i])-1):#class result is excluded  \n",
    "                if(array[i][j]==vocab):\n",
    "                    count=count+1;\n",
    "                    break;\n",
    "    dictionary={vocab:count}; \n",
    "    return dictionary;\n",
    "  \n",
    "#Probability of the occurrence of all vocab:\n",
    "def prob_vocab_in_document(array,v_list):\n",
    "    dictionary={};\n",
    "    for i in v_list:\n",
    "        d={};\n",
    "        d=count_vocab_in_document(array,i);\n",
    "        prob=d[i]/len(array);\n",
    "        dictionary[i]=prob;\n",
    "    return dictionary;\n",
    "\n",
    "def count_prob_vocab_in_document(array,v_list,review):\n",
    "    dictionary={};\n",
    "    p_n_dict=count_total_category_reviews(array);\n",
    "    for i in v_list:\n",
    "        d={};\n",
    "        d=count_vocab_in_document_review(array,i,review);\n",
    "        prob=d[i]/p_n_dict[review];\n",
    "        dictionary[i]=prob;\n",
    "    return dictionary;\n",
    "\n",
    "def cal_prob_from_dict(dic):\n",
    "    prob=1;\n",
    "    for i in dic:\n",
    "        prob=prob*dic[i];\n",
    "    return prob;\n",
    "\n",
    "dictionary_pos_neg_count=count_total_category_reviews(train_dataset);\n",
    "print(\"Dictionary with count of positive and negative in dataset\");\n",
    "print(dictionary_pos_neg_count);\n",
    "\n",
    "dictionary_the=count_vocab_in_document(train_dataset,'the');\n",
    "print(\"\\nDocument containing the\");\n",
    "print(dictionary_the);\n",
    "\n",
    "vl=new_vocab_list[0:10]#For testing prop function array:\n",
    "print(\"\\nFor testing prop function array:\")\n",
    "print(vl)\n",
    "\n",
    "dictionary_vocab_probability=prob_vocab_in_document(train_dataset,vl);\n",
    "print(\"\\nProbability of vocab in testing array vl created above:\")\n",
    "print(dictionary_vocab_probability)\n",
    "\n",
    "pos_dictionary_vocab_probability=count_prob_vocab_in_document(train_dataset,vl,1);\n",
    "print(\"\\nConditional Probability of vocab in testing array vl created above for positive review:\")\n",
    "print(pos_dictionary_vocab_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>D. Calculate accuracy using dev dataset </strong>\n",
    "* Conduct five fold cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40.0, 62.5, 55.00000000000001, 62.5, 30.0]\n"
     ]
    }
   ],
   "source": [
    "def divide_train_test_k_folds(array,k):\n",
    "    return np.split(array,k);\n",
    "\n",
    "def cal_k_fold_accuracy(array,k):\n",
    "    folds=divide_train_test_k_folds(array,k);\n",
    "    accurate=[]\n",
    "    for i in range(k):\n",
    "        #print(i)\n",
    "        a=0\n",
    "        \n",
    "        train=[];\n",
    "        test=[];\n",
    "        test=folds[i];\n",
    "        #print(len(test))\n",
    "        for j in range(k):\n",
    "            if(j!=i):\n",
    "                #train=folds[j].append();\n",
    "                train=np.concatenate((train, folds[j]));\n",
    "        vocab_list=build_vocab_list(train);#generate vocabulary\n",
    "#         vocab_list=remove_element(vocab_list, 5)#remove vocabulary with count less than 5\n",
    "#         vocab_dict=array_to_dict(vocab_list);#vocab array to dictionary\n",
    "#         rev_vocab_dict=reverse_index_dictionary(vocab_dict);#revrse indexing\n",
    "#         vocab_list=dict_to_array(rev_vocab_dict)#vocab dict to array\n",
    "        #print(len(train))\n",
    "        for i in range(len(train)):\n",
    "            #a[i]=(remove_element(a[i], 2))  \n",
    "            train[i]=(dict_to_array(reverse_index_dictionary(array_to_dict(remove_element(vocab_list,train[i],5)))));\n",
    "        #print(train[100])\n",
    "        dict_pos_neg_count=count_total_category_reviews(train);#count positive and negative reviews\n",
    "        for m in range(len(test)):\n",
    "            pos_dict_vocab_probability=count_prob_vocab_in_document(train,test[m],1);\n",
    "            neg_dict_vocab_probability=count_prob_vocab_in_document(train,test[m],0);\n",
    "            word_prob=prob_vocab_in_document(train,test[m]);\n",
    "            #print(word_prob)\n",
    "            pos_prob=(cal_prob_from_dict(pos_dict_vocab_probability)*(dict_pos_neg_count[1]/len(train)))\n",
    "            neg_prob=(cal_prob_from_dict(neg_dict_vocab_probability)*(dict_pos_neg_count[0]/len(train)))\n",
    "            if(float(pos_prob)>float(neg_prob)):\n",
    "                predit=1;\n",
    "            else:\n",
    "                predit=0;\n",
    "            if(int(predit)==int(test[m][len(test[m])-1])):\n",
    "                a=a+1;\n",
    "                \n",
    "                #print(accurate[0])\n",
    "        accurate.append((a/len(test))*100);\n",
    "    return accurate;\n",
    "\n",
    "k=5;\n",
    "acc=cal_k_fold_accuracy(t_data,5);\n",
    "print(acc);\n",
    "        \n",
    "# for i in range(5):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score for k fold cross validation:\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "#calculate mean of all k fold acurracy scores :\n",
    "sum=0;\n",
    "for i in acc:\n",
    "    sum=sum+i;\n",
    "mean_score=sum/len(acc);\n",
    "print(\"Mean score for k fold cross validation:\");\n",
    "print(mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>E. Do following experiments</strong>\n",
    "* Compare the effect of Smoothing\n",
    "* Derive Top 10 words that predicts positive and negative class\n",
    "    * P[Positive| word] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For smoothing we are going to use Laplace Smoothing. Basically it is done to avoid probability for feature where it becomes zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha=1\n",
      "With Smoothing:\n",
      "{'this': 0.2916666666666667, 'is': 0.3023255813953488, 'an': 0.2535211267605634, 'excellent': 0.10126582278481013, 'film': 0.2564102564102564, 'for': 0.2840909090909091, 'female': 0.03896103896103896, 'body': 0.05263157894736842, 'builder': 0.0273972602739726, 'action': 0.10588235294117647}\n",
      "\n",
      "Without Smoothing:\n",
      "{'this': 0.8611111111111112, 'is': 0.8888888888888888, 'an': 0.4861111111111111, 'excellent': 0.09722222222222222, 'film': 0.5416666666666666, 'for': 0.6805555555555556, 'female': 0.027777777777777776, 'body': 0.041666666666666664, 'builder': 0.013888888888888888, 'action': 0.1111111111111111}\n",
      "\n",
      "\n",
      "Alpha=2\n",
      "With Smoothing:\n",
      "{'this': 0.17777777777777778, 'is': 0.18435754189944134, 'an': 0.17452830188679244, 'excellent': 0.10465116279069768, 'film': 0.17083333333333334, 'for': 0.18214285714285713, 'female': 0.04878048780487805, 'body': 0.0625, 'builder': 0.04054054054054054, 'action': 0.10204081632653061}\n",
      "\n",
      "Without Smoothing:\n",
      "{'this': 0.8611111111111112, 'is': 0.8888888888888888, 'an': 0.4861111111111111, 'excellent': 0.09722222222222222, 'film': 0.5416666666666666, 'for': 0.6805555555555556, 'female': 0.027777777777777776, 'body': 0.041666666666666664, 'builder': 0.013888888888888888, 'action': 0.1111111111111111}\n",
      "\n",
      "\n",
      "Alpha=3\n",
      "With Smoothing:\n",
      "{'this': 0.12896825396825398, 'is': 0.13373253493013973, 'an': 0.1347517730496454, 'excellent': 0.10752688172043011, 'film': 0.12962962962962962, 'for': 0.13541666666666666, 'female': 0.05747126436781609, 'body': 0.07142857142857142, 'builder': 0.05333333333333334, 'action': 0.0990990990990991}\n",
      "\n",
      "Without Smoothing:\n",
      "{'this': 0.8611111111111112, 'is': 0.8888888888888888, 'an': 0.4861111111111111, 'excellent': 0.09722222222222222, 'film': 0.5416666666666666, 'for': 0.6805555555555556, 'female': 0.027777777777777776, 'body': 0.041666666666666664, 'builder': 0.013888888888888888, 'action': 0.1111111111111111}\n",
      "\n",
      "\n",
      "Alpha=4\n",
      "With Smoothing:\n",
      "{'this': 0.10185185185185185, 'is': 0.10559006211180125, 'an': 0.11079545454545454, 'excellent': 0.11, 'film': 0.1053921568627451, 'for': 0.10860655737704918, 'female': 0.06521739130434782, 'body': 0.07954545454545454, 'builder': 0.06578947368421052, 'action': 0.0967741935483871}\n",
      "\n",
      "Without Smoothing:\n",
      "{'this': 0.8611111111111112, 'is': 0.8888888888888888, 'an': 0.4861111111111111, 'excellent': 0.09722222222222222, 'film': 0.5416666666666666, 'for': 0.6805555555555556, 'female': 0.027777777777777776, 'body': 0.041666666666666664, 'builder': 0.013888888888888888, 'action': 0.1111111111111111}\n",
      "\n",
      "\n",
      "Alpha=5\n",
      "With Smoothing:\n",
      "{'this': 0.0845959595959596, 'is': 0.08767471410419314, 'an': 0.0947867298578199, 'excellent': 0.11214953271028037, 'film': 0.08943089430894309, 'for': 0.09121621621621621, 'female': 0.07216494845360824, 'body': 0.08695652173913043, 'builder': 0.07792207792207792, 'action': 0.0948905109489051}\n",
      "\n",
      "Without Smoothing:\n",
      "{'this': 0.8611111111111112, 'is': 0.8888888888888888, 'an': 0.4861111111111111, 'excellent': 0.09722222222222222, 'film': 0.5416666666666666, 'for': 0.6805555555555556, 'female': 0.027777777777777776, 'body': 0.041666666666666664, 'builder': 0.013888888888888888, 'action': 0.1111111111111111}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#comparing the effect of smoothing on probability:\n",
    "\n",
    "alpha=[1,2,3,4,5];\n",
    "#Here we are taking 1st sample from training dataset and built_vocab for comparison \n",
    "smooth_test=train_dataset[1]\n",
    "\n",
    "def count_smoothing_prob_vocab_in_document(array,v_list,review,alpha):\n",
    "    dictionary={};\n",
    "    p_n_dict=count_total_category_reviews(array);\n",
    "    for i in v_list:\n",
    "        d={};\n",
    "        d=count_vocab_in_document_review(array,i,review);\n",
    "        if(review==0):\n",
    "            review2=1;\n",
    "        else:\n",
    "            review2=0;\n",
    "        d2=count_vocab_in_document_review(array,i,review2)    \n",
    "        A=d[i]+d2[i];    \n",
    "        prob=(d[i]+alpha)/(p_n_dict[review]+alpha*A);\n",
    "        dictionary[i]=prob;\n",
    "    return dictionary;\n",
    "\n",
    "def alpha_smoothing_comparison(dataset,smooth,review,alpha):\n",
    "    for i in range(len(alpha)): \n",
    "        smooth_dict=count_smoothing_prob_vocab_in_document(dataset,smooth,review,i+1)#alpha=1\n",
    "        not_smooth_dict=count_prob_vocab_in_document(dataset,smooth,review)\n",
    "        dd={}\n",
    "        dd2={}\n",
    "        for x in list(smooth_dict)[0:10]:\n",
    "            dd[x]=smooth_dict[x];\n",
    "        for x in list(not_smooth_dict)[0:10]:\n",
    "            dd2[x]=not_smooth_dict[x];\n",
    "        print(\"Alpha=\"+str(i+1));\n",
    "        print(\"With Smoothing:\")\n",
    "        print(dd)  \n",
    "        print(\"\\nWithout Smoothing:\")\n",
    "        print(dd2) \n",
    "        print(\"\\n\")\n",
    "alpha_smoothing_comparison(train_dataset,smooth_test,1,alpha)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can seen values which are near to zero their probability increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top top positive words:\n",
      "(positive|a):0.1413716814159292\n",
      "(positive|that):0.13943661971830984\n",
      "(positive|the):0.13891304347826086\n",
      "(positive|and):0.13721973094170403\n",
      "(positive|is):0.13604651162790699\n",
      "(positive|it):0.135\n",
      "(positive|of):0.13395348837209303\n",
      "(positive|to):0.1323529411764706\n",
      "(positive|this):0.13125\n",
      "(positive|in):0.13125\n",
      "Top top negative words:\n",
      "(negative|to):0.19957805907172999\n",
      "(negative|the):0.1989837398373984\n",
      "(negative|this):0.19676724137931037\n",
      "(negative|in):0.19676724137931037\n",
      "(negative|and):0.19560669456066945\n",
      "(negative|a):0.1931818181818182\n",
      "(negative|of):0.19285714285714287\n",
      "(negative|is):0.1904761904761905\n",
      "(negative|that):0.1849344978165939\n",
      "(negative|not):0.18138297872340425\n"
     ]
    }
   ],
   "source": [
    "#alpha=1 gives promising solution:\n",
    "import operator\n",
    "\n",
    "p_smoothing_vocab_dict=count_smoothing_prob_vocab_in_document(train_dataset,new_vocab_list,1,1)\n",
    "n_smoothing_vocab_dict=count_smoothing_prob_vocab_in_document(train_dataset,new_vocab_list,0,1)\n",
    "p_sorted_smoothing_vocab_dict= dict(sorted(p_smoothing_vocab_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
    "n_sorted_smoothing_vocab_dict= dict(sorted(n_smoothing_vocab_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
    "dd_1={}\n",
    "dd_2={}\n",
    "for x in list(p_sorted_smoothing_vocab_dict)[0:10]:\n",
    "    dd_1[x]=p_sorted_smoothing_vocab_dict[x];\n",
    "for x in list(n_sorted_smoothing_vocab_dict)[0:10]:\n",
    "    dd_2[x]=n_sorted_smoothing_vocab_dict[x];\n",
    "    \n",
    "p_n_count=count_total_category_reviews(train_dataset) ;   \n",
    "#P(positive|word):\n",
    "\n",
    "print(\"Top top positive words:\");\n",
    "for i in dd_1:\n",
    "    print(\"(positive|\"+str(i)+\"):\"+str(dd_1[i]*(p_n_count[1]/len(train_dataset))));\n",
    "    \n",
    "#P(neagtive|word):  \n",
    "print(\"Top top negative words:\");    \n",
    "for i in dd_2:\n",
    "    print(\"(negative|\"+str(i)+\"):\"+str(dd_2[i]*(p_n_count[0]/len(train_dataset)))); \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>F. Using the test dataset</strong>\n",
    "* Use the optimal hyperparameters you found in the step e, and use it to calculate the final accuracy.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy:\n",
      "96.0%\n"
     ]
    }
   ],
   "source": [
    "#Calculate accuracy on testing dataset where alpha=1\n",
    "alpha=1\n",
    "acc=0;\n",
    "for i in range(len(train_dataset)):\n",
    "        train_dataset[i]=(dict_to_array(reverse_index_dictionary(array_to_dict(remove_element(vocab_list,train_dataset[i],5)))));\n",
    "        dict_pos_neg_count=count_total_category_reviews(train_dataset);#count positive and negative reviews\n",
    "        for m in range(len(list(test_dataset)[0:5])):\n",
    "            pos_dict_vocab_probability=count_smoothing_prob_vocab_in_document(train_dataset,test_dataset[m],1,alpha);\n",
    "            neg_dict_vocab_probability=count_smoothing_prob_vocab_in_document(train_dataset,test_dataset[m],0,alpha);\n",
    "            word_prob=prob_vocab_in_document(train_dataset,test_dataset[m]);\n",
    "            #print(word_prob)\n",
    "            pos_prob=(cal_prob_from_dict(pos_dict_vocab_probability)*(dict_pos_neg_count[1]/len(train_dataset)))\n",
    "            neg_prob=(cal_prob_from_dict(neg_dict_vocab_probability)*(dict_pos_neg_count[0]/len(train_dataset)))\n",
    "            if(float(pos_prob)>float(neg_prob)):\n",
    "                predit=1;\n",
    "            else:\n",
    "                predit=0;\n",
    "            if(int(predit)==int(test_dataset[m][len(test_dataset[m])-1])):\n",
    "                acc=acc+1;\n",
    "\n",
    "accuracy_percentage=(float(acc)/float(len(test_dataset)))\n",
    "print(\"Final Accuracy:\");\n",
    "print(str(accuracy_percentage)+\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Reference:</strong>\n",
    "<br/>Tokenization: https://www.analyticsvidhya.com/blog/2019/07/how-get-started-nlp-6-unique-ways-perform-tokenization/?utm_source=blog&utm_medium=how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python\n",
    "<br/>How to split the dataset into 3 parts: http://cs230.stanford.edu/blog/split/\n",
    "<br/>Video using libraries: https://www.youtube.com/watch?v=0kPRaYSgblM\n",
    "<br/>Text classification guide: https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n",
    "<br/>Why to take less than 5 occurrence words: https://www.analyticsvidhya.com/blog/2015/10/6-practices-enhance-performance-text-classification-model/\n",
    "<br/>Help for Part A and B: https://machinelearningmastery.com/gentle-introduction-bag-words-model/\n",
    "<br/>K-fold cross validation: https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/\n",
    "<br/>Smoothing: https://www.researchgate.net/publication/314668326_Comparison_of_Naive_Bayes_smoothing_methods_for_Twitter_sentiment_analysis\n",
    "<br/>Smoothing 2: https://medium.com/syncedreview/applying-multinomial-naive-bayes-to-nlp-problems-a-practical-explanation-4f5271768ebf\n",
    "<br/>Fetch Data from txt files: https://machinelearningmastery.com/prepare-movie-review-data-sentiment-analysis/\n",
    "<br/>Remove k times repeated element from array: https://www.geeksforgeeks.org/python-remove-elements-of-list-that-are-repeated-less-than-k-times/\n",
    "<br/>Split array in k folds: https://stackoverflow.com/questions/2130016/splitting-a-list-into-n-parts-of-approximately-equal-length\n",
    "<br/>Sorting dict by value: https://www.w3resource.com/python-exercises/dictionary/python-data-type-dictionary-exercise-1.php"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
